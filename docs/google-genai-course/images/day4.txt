DAY 4 Livestream - 5-Day Gen AI Intensive Course | Kaggle - YouTube
https://www.youtube.com/watch?v=AN2tpHi26OE

Transcript:
(00:01) hello everyone Welcome to our fourth day of the kaggle generative AI intensive course where we have been teaching over a quarter of a million of you developers out into the world all the things that you would ever want to know about generative Ai and how to use it as part of your projects I am so excited to be here today with our expert panel of guests and all of the folks who are um around Google uh Google Deep Mind Google Cloud kaggle um all sorts of places in uh an alphabet who have come together to build this course and to make it a
(00:31) reality so just as a general reminder um this course is a 5-day generative AI intensive sponsored by kaggle um it includes daily assignments things like Discord discussions as well as Cod laabs um we are on our fourth day of the course which is focused on domain specific large language models um so showing how you can fine-tune models to to meet the needs of your projects and uh I want to give a huge virtual Round of Applause and thank you to our wonderful gen course moderators they have been working tirelessly around the
(01:05) clock to answer your questions to make things uh to make things perfect for our code Labs um and I just want to to make sure that they all get recognized so thank you so much to everyone especially our Ops Team um Brenda Flynn and Kel perk who have been uh tirelessly um again just uh pushing through to make this happen and giving a lot of love to the course um so with that I am going to hand it over to an not who is going to give a brief curric ulum overview of all of the white papers that yall have been reading over the last few days thank you
(01:35) Paige so hi everyone so welcome to day four so uh in my curriculum overview I'll just start off by mentioning what we have done last few days for instance uh in day one we looked at how foundational models take uh and various topics such as uh techniques to tune them make them run efficiently as well as prompt engineering to get the desired outcome then in day two two we looked at how data can be embedded in their semantic representations and search fall at scale using Vector databases and then in day three yesterday we looked at how
(02:11) all of this can be combined and extended to make agents which can dynamically make decisions and interact with the external worlds in order to achieve their objective now today in day four we are going to look at how all of these Concepts that we learned in the previous days can come together um and being uh uh used to make specialized domain specific models so let's get uh to the recap of the white paper for today so first we read in the white paper that General llms often need specialization for Fields like cyber security and
(02:44) medicine as well as more these areas have unique data challenges technical language as well as sensitive requirements that demand this adaptation or can benefit from it then we saw we started off with the cyber security example with secm it tackles evolving threats and list toil and talent shortages by combining specialized models tread intelligence as well as automated reasoning to assist Security Professionals training involves adding security data and fine-tuning and relevant tasks and some more then we looked at the section uh on medicine
(03:19) which features medm and Med pom these models address the challenges of navigating vast medical knowledge for tasks like high quality medical Q&A and supporting clinical workflows Med p 2 for instance showed expert level performance on medical exam uh benchmarks a key to this field is rigorous rigorous evaluation and we read about this for instance using specific benchmarks and expert clinician reviews plus careful phased real world testing as well now training involves uh um instruction fine-tuning on medical data
(03:54) and advanced prompting strategies for these two models the white papers then basically towards the end concluded that uh with the fact that uh successfully deploying these powerful tools requires not just specialized models but also deep collaboration with domain experts and thorough step-by-step evaluation to ensure safety and Effectiveness in these critical Fields so that would be the summary of what you read in today's white paper and off to you page for the Q&A amazing and that is super exciting I loved learning all about uh how we can
(04:27) fine-tune models and make them great for things like cyber security and things like healthcare um and with that we're going to go in our Q&A session so I am Overjoyed today to welcome Scott Chris caric Eva and Donnie um to talk about the work that they're doing around Google around Google research uh Google deepmind and Google Cloud um and to tell us a little bit more about these fascinating topics um and all about fine-tuning in how to make it real in production environment so welcome so much uh today um for our first question
(05:00) question uh Donnie this is for you um from a research and Engineering perspective what are the most effective strategies for specializing llms is it better to fine-tune large general purpose models to train smaller models from scratch on domain data or use techniques like uh um parameter efficient fine-tuning do these choices uh kind of impact performance cost um and how do you keep the models updated over time um so lots of lots of questions embedded into a single one you want to take that thanks so much Paige
(05:33) so what we found over time especially in our experience uh with building medp medm um is that there isn't one best way to specialize a large language model for a task and that the best method really depends on the nature of the task the complexity of the task and of course like the amount and quality and the nature of the data that you have available to you um the best way to figure out which method works best is uh well first of all you can look at similar problems other things people have tried things in the literature and
(06:00) see if any of those are a good fit and then try that first but ultimately you really just have to experiment and see what works best you have to test different methods and and see see what works well of course you know the less compute that you need to achieve your goals the better right that allows you control your costs that also allows you um to keep your uh you know give give you gives you the ability to keep your model better updated if if it's cheap to to retrain but some complex use cases will require regular updates of new data
(06:27) and so you'll be you know you'll have to be training uh regularly to to keep that model updated so that affects the update ability as well thanks for the question awesome and uh I know that um I I often have seen people ask uh unfin tuned models so just the the Gemini models or others like it medical questions um or things that are are similar to healthcare and grounding on PDF documents or other kinds of data um would you recommend that people always start with kind of prompting the the unfin tuned model before uh diving into
(07:02) fine-tuning their own it's always good to see what the the base capability of the foundation models are um I think in specialized domains I think you'll find quickly that there are going to be limitations especially if you're thinking about uh you know about deployments especially in clinical scenarios that you're going to test the foundation models they're going to be very good uh at many many many tasks but there's going to be specialization that you're you're you're going to find once you kind of Hit the edges of what the
(07:28) the foundation models are capable of there are of course use cases where the foundation models are going to are going to do very well and and that will you know that can be the end of it and you can use those in your applications y I love being able to to kind of turn all of these knobs and dials to to get a model that's really really compelling for a business use case um and that we have this flexible series of approaches across um just using models out of the box and then also customizing them for user needs so that's that's very very
(07:57) cool thank you so much for your answer um our next question is a community question um from Yan thean um during the fine-tuning code lab I observed significant token savings however there are scenarios where fine tuning can are there scenarios where fine tuning can unintentionally reduce uh the generality or creativity of a model and how do teams evaluate when to fine tune versus when to use prompts or retrieval so very very related to the last question that we were discussing um Chris do you want to talk about this one yeah sure um
(08:30) I think this is a this is a great question and there's definitely problems that you're going to encounter when you when you start fine tuning um especially you know there's a there's a problem that you'll probably here commonly referred to as catastrophic forgetting which is sort of kind of the the worst case scenario you you encounter when you're fine tuning where you've gone too far and the model can't do other things anymore it's only able to do kind of the very specific task that you find tuned on um and there's of course you know
(08:55) kind of a gradient in between the foundation model and the you know the the kind of worst case scenario I just described um but especially when it's when you're fine-tuning it's really important to have a thorough evaluation around a range of tasks that you're going to be doing not just the task you're necessarily fine-tuning but what what other possible scenarios you're going to be using it in so you can understand kind of the the quality either gains or losses depending on how you've been fine tuning on those sort of
(09:20) adjacent tasks um generally when we're doing this in security use cases uh we aim for a range of evaluation tasks and also a range of fine-tuning tests so we want to teach it general concepts during fine-tuning and then be able to sort of use the generality of those those those Concepts again at you know at deployment time or at run time it gives us kind of a mix of both um but really evaluation and I think you're going to hear this in a few different areas this morning but evaluation is key in a lot of these kind
(09:48) of domain specific areas awesome and Scott did you want to add something yeah absolutely so just to build on sort of Donnie and and Chris's answer here I I always go back to I know this it maybe this is like not not the cool thing to do but I always go back to like the the first principles of like ml right so does the model you know is the task that I'm doing in distribution for the model was it was it trained on the thing and on the data that I expect it to operate on I think that's really the the key question when it comes to fine-tuning
(10:18) and and which level of fine tuning whether it's full parameter fine tuning or something is parameter efficient like Laura or other methods um so I think one thing you'll you'll find is a really great paper out there called the reversal curse um it kind of starts talking a little bit about where in this stack of training you can start to actually get really good generalizable knowledge and sort of the further down you go from you know pre-training through fine-tuning through you know alignment and now into you know
(10:47) parameter efficient techniques like the less and less generalizability you get and the more like forgetting you tend to get and the more honestly the more in distribution your task has to be in order for it to be successful uccessful so I think that's one of the big questions to really think about when you're when you're talking about kind of like to what degree do I need to fine tune is really like well do I already expect this to be in the training data somehow and if so then maybe I don't need to do that much to just nudge the
(11:13) model a little bit in the direction that I want it to go and if not then probably something more significant is going to be necessary and we'll have to do that more carefully to not forget some of the Baseline capabilities amazing and we'll put a link to that paper that you uh that you recommended into the into the YouTube video and some of the notes for the course as well I love that answer excellent thank y'all this is a great start uh for our Q&A um next question uh also for Chris um so When developing llms for security domains like secm what
(11:44) are the biggest challenges in acquiring and using relevant high quality data for fine-tuning um given its sensitive or proprietary nature how do you measure success and ensure these models improve security operations without introducing new risks so it's a very even Val's heavy discussion this morning yeah definitely I think that's great though um so we we know that providing accurate and useful security advice is really hard um you know there's a lot of convicting opinions online everybody has sort of different
(12:15) ways of approaching security and it's also something that really needs to take the kind of environment and situation into account um you know thinking about people at home you know and email security is very different than thinking about code security and other sort of Tas and so we we do need to kind of uh sort of have different kinds of data sets for different kinds of tasks and often times those data sets are um are proprietary or or or sensitive in in some way so what we've sort of done with building cm is have a chance to
(12:46) experiment with that whole Spectrum so everything from training and fine-tuning on models where we are using heavily um you know large large amounts of U internal information about secur and threat actors and sensitive you know sensitive material there all the way to the kind of the other end of the spectrum using basically Foundation models more or less off the shelf um and that gives us a really sort of nice Spectrum to sort of pick pick and place to work um and so what we've seen is that the best performing approach for us
(13:17) is kind of sort of in the Middle where we're doing um training with plenty of high quality public security information um and that's really feeding into you know into the foundation models into Gemini itself in this case um and then we layer on runtime techniques like rag that doesn't mean we don't need fine-tuning we do think about fine tuning absolutely as how to make these tasks perform well but we tend to fine-tune in a way where we're looking at sort of understanding a generalized task rather than maybe memorizing
(13:44) specific information so it's it's not about necessarily the recall given you know the recall against a specific threat actor or other s sort of piece of material but being able to converse and answer correct questions accurately giving the grounding material for about that particular factor in that that in that situation um the other the kind of other element of sort of coupling these training fine-tuning and runtime uh runtime uh techniques gives us a really nice way to also give our our users other sorts of benefits so features like
(14:17) citations provide a lot of user confidence in sort of what the model is telling them you know if we if we give people advice you a in a security Direction you know you should change your password so and so often it's really great to be able to point to a policy a document research other things that that kind of vouch for that particular uh that that particular statement um and so that that's one way that we do this and of course evaluation on this again is key so evaluating with uh with that grounding material without
(14:45) the grounding material um all of that sort of thing you're going to build out really good evaluation data sets for understanding really just how how good you are at the different security specific tasks with and without that proprietary information and that's a great great answer and for folks who are curious about evals um the next day is going to be discussing them in depth so make sure to tune in tomorrow as well for um for more discussion about evals um I also really love citations I use them all the time um both uh when grounding with
(15:16) Google search so being able to see kind of the up-to-date and relevant information that the the model is using to help ground its outputs um as well as grounding on uh on internal data sources I love being able to to kind of click and get to a PDF document or something similar um to to get more confidence in the models answer um awesome next question this is for Eva um Healthcare and Life Sciences is a domain with complex terminology high stakes for accuracy and significant regulatory considerations what unique challenges
(15:48) and opportunities arise when building or fine-tuning large language models for these healthc care applications and how do you ensure that the model is reliable that it has high uh High safety um and also compliance um thank you Paige so we've been hearing a lot about the challenges so why even do Dom main specific uh llm so let me start with the potential I think that the potential is immense think about personalized medicine think about scientific discovery improved clinical documentation more effective Health Care processes there is so much
(16:23) potential that building those llms brings and uh hopefully many of you are are looking at how we can bring this technology into the space of healthc care and Life Sciences uh the challenges unfortunately are still pretty hard and unique uh complex domain specific terminology uh if you think about how two doctors talk to each other none of us could understand that and the llms need to be able to actually understand that new terminology high accuracy demands this is actually a life and death situation in many cases evolving
(17:02) knowledge landscape uh the science both the Medical Science and the life sciences evolve and new discoveries come up every day so the stale information becomes inaccurate there is uh data scarcity uh need for causal reasoning um and really stringent regulations um so the opportunities lie in automating tasks accelerating research and improving patient interactions uh it's really important to ensure reliability safety and compliance and in order to do that we use a multifaceted approach this includes curated data with
(17:40) strong governance uh rigorous model evaluation with uh specific metrics uh and expert validations uh we're priori prioritizing explainability implementing robust safety measures against uh harmful and uh harmful continent biases uh and adhering to all regulatory requirements uh uh there is a necessity for interdisciplinary collaboration and continuous monitoring so not just at training time and fine-tuning time but you want to continue more monitoring the systems after deployment awesome that's uh a lot of wonderful things to consider when uh
(18:22) when building these Healthcare and Life Sciences AI systems so thank you for going into depth uh for all of the things that Engineers might want to be mindful of um next question is for caric uh welcome uh welcome to the call uh how do you balance the need for deep domain expertise within the model um against the risk of things like catastrophic forgetting which we heard about out a little bit earlier um or over fitting on specific training data um are techniques like rag or using the context window sometimes a better alternative or a
(18:54) complement to fine tuning for domain adaptation thank you for the question really great question um I think let me answer that in two parts uh let's start the first part right uh some of this was discussed by Don and Scott and CHR and like the first set of answers right I think there are some very important practical considerations uh when you make some of these choices and it depends on how you plan to use the final model what is the domain and specific applications of this model if your goal is a very specific
(19:26) very narrow task that you you don't run the risk of sort of needing a lot of general purpose knowledge it is okay to sort of go with a more heavy-handed fine-tuning approach per se uh because you you there usually isn't too much in terms of a tradeoff outside of computation budget um but a lot of tasks that do need more open-ended more knowledge heavy tasks do sort of need a more gentle measured touch because you do really want to sort of make sure the model is not losing some of the general purpose knowledge because again as
(20:00) already we discussed the more you find tune the risk you run of sort of losing some of that knowledge so uh I think there also is a consideration in terms of the outof boox skills for the base llm on the specific domain or application um a domain that is more commonly represented say perhaps in the preing data is going to be something which is better models are going to be better at say something like code uh then they would add if I ask you something a very esoteric domain per say I don't know Nuclear Physics or some s
(20:36) like that so um I think that is another consideration when you're sort of trying to determine this uh how common popular how good are the outer box skills of the base model before you sort of try to go further down the fining crout uh in recent years I think the LMS have advanced enough that the pendulum has swung a lot more towards light touches parameter efficient fine tuning uh just because again the base models have become much more powerful Learners and the need for sort of more heavy-handed tuning has really sort of gone down as
(21:14) base models seem to be able to learn much faster with far less data or in some cases just out of the box the second part okay this is really great I love I love this question um because I think techniques at CAG are somewhat underused honestly uh newer models have become much better at using the information provided in the context um I I can I'm reminded of an example a demonstration that was about a year ago per say right where someone took a grammar manual for this language called Kang which has only fewer than 200
(21:52) speakers worldwide they added that to the model in a single prompt and the model learned to translate from English to calang at a similar level as speakers of that language which is crazy to think about it right there's no fine-tuning nothing you just gave it the manual uh I think this is an increasingly important capability of models techniques like in context learning really allow the model to solve new complex tasks with just a few demonstrations and again this is a very actively growing area of uh new models
(22:28) as they come about and like if anything I expect performance only keep improving in these areas rag is another technique in the same V right where you can putting a lot of valuable information into the context and hope that the model can learn from those valuable pieces of uh the Snippets information they have provided there at the end of the day there's also a practical question here um are you willing to pay the inference cost because typically when you have techniques like Rag and Conta learning you are working with slightly longer
(23:01) prompts um it again here too I feel the pendulum is swinging more towards allowing these techniques just because techniques like prefix caching and other optimizations and inference mean that LMS have become a lot better at dealing with such longer context the older days of Transformers like we no longer in the quadratic attention setting where like you can you can't scale up to super long sequences I mean the gem models can handle up to tokens easily so I think it then Gates on your ability to find useful information and again this
(23:36) tends to depend a lot on the actual specific problem and domain so yeah y i I love that and a m I am a huge fan of Gemini's long context window especially for things like pulling in entire code bases um similar to the example that you gave um I've really loved being able to pull in cobal code bases along with just kind of an instru instruction or a documentation manual um and then suddenly Gemini knows cobal or it knows cobal much better than it did before um so if folks are a little bit time crunched and they don't necessarily
(24:09) have the ability to uh or the TPU resources or GPU resources to do fine tuning I think sometimes testing out things in the context window is a is a really great first um kind of prototyping phase as opposed to as opposed to to starting immediately with fine tuning awesome uh next question is our second Community question from unar how is data grounding handled when external knowledge bases are real-time data streams what is the accuracy level um for um for those systems and Scott do you want to take a take a stab at this
(24:45) one yeah absolutely um so I don't think I have any good metrics that I can share in terms of accuracy levels I do I do I can say that for secm um that sort of grounding information is incredibly important for all the reasons Chris mentioned at the very beginning um just the the amount of change that happens in this domain from even hour to hour in terms of you know Frontline observations of attacks and threats is really important to be able to bring that information in in a sort of a real-time fashion I you know I kind of I don't
(25:17) know maybe others on the call Will Will kind of feel differently here but like the realtime aspect actually doesn't change much in my mind in terms of how you deal with the data right ultimately you're still going to want to perform retrieval right which means taking whatever is in the prompt from the user and kind of matching it up against this data somehow right so you can imagine caching mechanisms or other data stores that you would sort of update over time as you get the you know new new items in the Stream and so on and so forth I
(25:46) think actually if I might Co-op this question slightly though I think one interesting thing to think about here is like specialized versus less or sort of generalized grounding kind of ideas um you know I think there's you know an interesting kind of Distinction here where you know you have Google search grounding which allows you to obviously get a large amount of relatively generalized information about a topic and then you have you know a little bit more cost that comes in with like a specialized knowledge base right so you
(26:20) know in secm for instance we use um you know we use our internal mandiant uh threat intelligence uh graph as part of our augmentation um and you know one of the interesting things here is like sometimes the way in which the Cyber SEC cyber security community refers to something is like fairly General so there's a lot of naming For Thread actors of things like cozy bear or like I don't know like winter Sandstorm there's a bunch of these kind of uh a little bit odd uh actor Notions and if you just go and search these things up
(26:56) on you know Google search grounding you're going to get a whole bunch of really unrelated uh pieces of grounding information right now the model usually can sift through these things and kind of identify when it's useful and when it's not useful but sometimes they can and sometimes you get some pretty wacky stuff so I think one interesting thing to think about here is is you know your kind of domain separation in some ways where you do have your very well defined authoritative sources where you kind of curate it and make sure it's very high
(27:26) quality and sort of use that as your primary source of information and then you have something like Google search grounding which you can use to kind of shore up any gaps that you might have in the the underly knowledge store um I will say one thing that the real time uh kind of probably introduces here that maybe I missed a little bit the first part which is the sort of temporal nature right which is that you know you could see many examples of the same entity pass through of this this you know real time stream with like updated
(27:56) information over time um you know I think there there's an interesting uh sort of engineering question there about how to integrate that best but again to me this feels a lot like a you know how do you keep your database up to date or how do you keep n you know replica replicas of the last you know iterations of some entities updates in this realtime stream in your in your database and retrieve them effectively or at least uh you know show it to the model in a way that it kind of captures that temporal change uh for that model over
(28:28) or for that entity over time I love this discussion about retrieval and kind of augmenting the models outputs with uh with up-to-date information and hopefully folks remember back to day two where they learned all about Vector databases and embeddings um and grounding models H in uh in data sources so this is this is great discussion um next question um Google Cloud security uses seim technology which integrates Google secops Google AI infrastructure and mandian thread intelligence leveraging tpus how do you
(29:02) manage the space complexity um Scott do you want to take this one yeah very carefully um yeah the the you know again you know I always try to boil things down to like what's what's existed in the ml space for many years right so I think tomorrow is the ml op session and I think there'll be a lot more discussion about some of these Concepts in that in that section but like in my mind a lot of this complexity eventually boils down to a real really really challenging case of mlops right so in a traditional ml system you have to
(29:34) monitor your data sources to see if there's changes right you have to keep your model up to date and do various types of evaluations in both real time and offline to ensure the quality of your model doesn't degrade over time these same things exist right maybe this time you don't get to choose when the model up updates or choose the level of degradation that you that you can absorb right but at least you can monitor all these things so at the end of the day it really comes down to like you know having these processes but at a pro at a
(30:06) level that's like much more expansive right so in the past if you had like let's say an image recognition system you'd have a stream of new images coming in that you would evaluate against maybe you you know cut off some some subset of them to train well here now you're getting you know you have all of your input feeds right so anything that you're using from a tool or from a rag store that you have to monitor which could be many many sources for for secm for instance we have I don't know at least half a dozen or more um different
(30:37) API feeds that we that we monitor um you have your other sort of static rag stores you have Google search grounding you have the models themselves which actually you know uh from version to version can demonstrate some pretty substantial behavioral changes and you basically have to be able to evaluate in a in an aut automated fashion like all of these things and still be able to actually pinpoint you know hey this thing is degraded on code use cases this thing is degraded on our threat Intel use cases and then be able to sort of
(31:09) further unravel the sort of knot and say okay well if it's a threat Intel you know regression like okay was that because the data changed was that because the model is not operating the same way on that same data that did in the past um is there new data that that didn't previously exist or you know another you know we talked about the temporal uh aspect in the last question that also plays here right which is yesterday an IP address or a host name or you know domain might actually have been considered malicious because at the
(31:42) time it was actually doing malicious things and in that time between yesterday and today's eval that might have changed completely right that that might have been mitigated or someone may have put some other uh remediation on it and now it's no longer malicious and all these things kind of have to be wrapped up in some holistic eval system so you can kind of really understand what role each component of your system plays and and how you can address it uh to kind of keep high quality amazing as a distributed systems
(32:12) nerd this makes me very excited but also very apprehensive so this is this is great uh this is great to hear um and it also uh it also I think is a lot more sophisticated of an approach than what we saw you know even just a couple of years ago when people were first starting to test out these large language models um it's really wonderful to see how models now are just becoming part um of a system that uh that's a bit more representative of real world use cases as opposed to to just being the endall and Beall um so this is this is
(32:45) wonderful thank you for the great question deina car um next question um from CX Wong what are the design considerations on when to apply a domain specific large language model versus generic llm and hybrid situ situations and use cases or are there hybrid architectures available that combine both and we've already touched on this a little bit uh caric and Eva do you wanna do you want to take a step sure I guess I can jump in uh so yesterday uh you heard a lot about agent architecture so obviously agent architectures are a great way to combine
(33:22) General uh and more specialized models into a hybrid solution if you think where the strengths of a general model are they're in the con conversational list kind of the user interface uh to a deeper system and then if you have an orchestrator you can easily have multiple domain specific llms behind that orchestrator and you can keep those llms much smaller uh and specialized by not even necessarily having the general knowledge because with Gemini's large context window the or orchestrator can bring in the right domain information
(34:01) and your generalist conversationalist can actually translate that into a language or a process that's more General so so that's probably um the best type of hybrid architecture is using an uh agent type of architecture and this also allows you to bring in data um and kind of deploy rag um type of approaches uh to augment uh with additional information in real time um so cartic do you want to add some yeah thanks I think that's that's a really great answer so um I think the only thing I would add to that is it it would
(34:43) depend a little bit on sort of like things like practical constraints like compute or sort of like the complexity of the system you're targeting um agentic architectures are really sort of where the world is moving towards per se but it do not necessarily always like the easiest things for folks to start with quickly play around get a quick dir solution per say um again IA mentioned rag as well that's that's a really nice way of thinking about it um I think it depends a lot on how deep domain knowledge a specific task would
(35:17) need which could influence the solution if I give example earlier of sort of if you had Medical Professional speaking in their Jaron per that's not really something which is very easy for us to sort of have a general purpose than figure out this is what is being meant by uh person a when they speaking to person B right and I think that is uh I think where some of these decisions um need to be sort of like factoring in sort of like how much deep domain knowledge is needed but again I think the hybrid architectures like as AA said
(35:48) like which agentic uh like more agentic settings are offering is really where I see the world moving yeah amazing like I I think this is um this is wonderful to have these kind of coupled approaches that help real people solve real problems so thank you both for the excellent answers the next question is from Batman Batman um so so we have uh we apparently have a superhero on our Discord channel uh with the rapid advancements and large language models for domain specific applications what are the key limitations preventing their
(36:21) widespread adoption in critical Industries like healthcare and finance and how can we Bridge those gaps um Donnie you want to talk about this in the healthcare domain absolutely um my toddler will be very excited to know that I answered a question from Batman today um so I'll talk mostly about healthcare because that's the domain I know the most but I will say that in the financial services there's a there's a very strong parallel in terms of Financial Health and financial data leading to to assessments of Financial
(36:49) Health that that are very applicable here as well um so I'll kind of break down the the key limitations into three categories um one of them is just the the complexity of the domain which I think Eva has already talked about and the solutions that she talked about were exactly the things that we actually had to do for medal metm right to evaluate with expert evaluations a lot of that had to go into making Med Med palm and metm things that we felt comfortable uh letting developers have access to um the second layer of complexity is really a
(37:20) complexive solution if you think about a you know a health encounter a clinical encounter the the model the model prediction is just a very small piece of how that integrates into an entire solution an entire workflow and you know we talked previously about agentic architectures we haven't really completely solve the problem of what are the right types of architectures or what types of agentic techniques need to be brought to bear in order to solve a a a system problem or a solution workflow level problem uh you know within within
(37:48) a healthare system and then I think the last layer of complexity is really systemwide complexity and here it's not just like you know even if you have a Deployable solution even if you have oh yeah we can you know for this particular use case we can do the same thing that a doctor does there are so many stakeholders within uh within the health system not just regulatory which AA also talked about um you know like healthc care payers governments Hospital Systems patient advocacy like a lot of stakeholders need to have their concerns
(38:18) listened to and understood within the framework of that solution and you know and and and making sure that the solution uh has you know you know respects all these different state holders and their needs is also uh immensely complicated so thinking about bias compliance usability explainability of the solution safety um you know the ability to integrate um you know across across a lot of different platforms so all of those factors come together to to Really amp up the complexity of of the solutions and the the needs here
(38:50) thanks amazing and that was our last question for today thank you so much to everyone for for um kind of discussing everything that that you're building and everything that you're creating in the research and the production World um I really loved the conversations around agent and hybrid architectures in the medical domains um and Healthcare as well as in uh the security World it sounds like a a really honestly very fun and exciting time to be working on these systems um Chris and Scott did you have anything that you wanted to add about
(39:20) these these kind of agent and hybrid architectures yeah I mean I I think I our our Journey on the secm side is probably very similar to the metm side right I think we learned very very early on in the in the process like whatever 20202 or whenever we started kind of really going down this path um is that you know one one model probably will not solve at all right we can't do the Lord of the Rings here with the model and so um it we we definitely got to sort of this agentic uh sort of tool use style architectures very very quickly because
(39:53) it does allow us to kind of very pointedly inject kind of exactly the expertise we we need and exactly the right places right now I think Paige and others have have said that there's definitely like a tradeoff here right like you're kind of you're trading off like the Simplicity of just having the one model and doing the one thing and being able to capture that very nicely with eval uh with something that's more bespoke and definitely going to have more technical debt associated with it but it's going to be probably more
(40:23) well-designed to exactly the use cases you want and I think that's very important when considering the sort of fine-tuning aspect of of the llms absolutely so with that um thank you all so much um for coming and for um for sharing everything with us today and for sharing all of uh all of the the things that you've built with our over a quarter of a million of developers out in the world um we really appreciate you thank you for taking the time um and we can't wait to to kind of test out all of the great products that you've
(40:55) recommended um so uh have a great rest of your day um and we'll get right into the code Labs um where folks can learn how they can start building all of these experiences and approaches into their own projects um so thank you uh and an not uh dive into the uh dive into the notebooks I'm really excited to learn more thank you paig I'm sharing my screen now um all right so we had two code labs for today uh covering a lot of the concepts that we talked about in white paper and this super interesting discussion actually so yeah let's dive
(41:32) into it so the first code lab um I'm going to be discussing is the one about fine-tuning a custom model uh and this code lab in this code lab we're going to be just uh using the same data set the new group data set from day two uh where we used an embedding model and train the caras model on top of it uh in this time around we'll be using Gemini both the base Gemini as well as the fine- tune Gemini for this particular classific application task so the problem Remains the Same but we using a different approach uh to to solve it so uh moving
(42:06) on um so in the first part of the code lab and just like in day two's code lab we download the news group Text data set and this basically has some news group posts um which uh which can and there which need to be classified into their respective um News Group categories or news groups and um you can download this data set the train and test subsets of it and yeah so for example these are some news group uh news groups or News Group categories which uh we expect the model to classify correctly against so um the next part of the uh collab we
(42:43) prepared a data set to both clean the news group uh posts which are being fed as the input to the model however there's also another aspect to it uh the cleaning helps us or pre-processing helps us prevent um the model from shortcutting um or directly from the text to the um to the T Target News Group made uh so because sometimes um there you known users of a forum can be used to guess which News Group the text belongs to so we we want to test the ability of the model and it's ability to understand the context so we are removing that
(43:21) additional information from the text then after all the pre-processing it looks something like like this the data frame uh where there text and the respective News Group um news groups or News Group categories and then uh now we are going to train parameter efficient fine-tune the Gemini 2.0 sorry 1.
(43:43) 5 model and in this case we will keep 50 rows from each category for training um we need now keep bear in mind these 50 rows are significantly less than the amount of rows we used for chaining the Kos on top of the embeddings um in uh K model on top of the embeddings in day two that's because uh the model the base model already has quite a lot of knowledge embedded into it and we do not need to um uh use a lot of data to to fine-tune it with parameter efficient techniques so um so this is what we do um here um and then before we get
(44:21) started with tuning and like evaluating the tune model it's good to always have a baseline in this case our Baseline could be uh should be as well the the um the base model with just a zero shot classification approach so if he uh if you just pass in the text the news group text as an input it basically um uh gives an answer to the to the question uh or gives an answer to this basically if you give it a text it does not give you the class we do not want it to answer to the news group post we want it to classify it so here's where your prom
(44:57) engineering Knowledge from day one comes into play where you ask you give give it a prompt like which what news group does the following message originate from and using Gemini 1. flash we see that it starts giving some news group it is quite verbose we just want the news group we do not want any extra information so you could also um try and Par out the relevant text or refine it further by giving it some role the role prompting which we learned in day one and um and um and then you see that it gives slightly like more more concise
(45:32) responses but this is not always correct still so if we evaluate the overall accuracy of uh across a test set of just using a zero shot um prompting for classification we see it's um not not very high and now if we tune a uh we do parameter efficient fine tuning on Gemini flash um 1.5 flash then we see improves the results significantly and there are a few knobs that you can tune uh such as Epoch count which tells how many times the model through the data batch size and more which you can use to get better results they they would you
(46:10) need to uh just like in predictive models you need to play around with them to see how how much they can improve the performance now so after um after um the new model has been um tuned or the parameter efficient fine- tuned you see that the perform performance improves significantly and that's where you see that in such scenarios parameter efficient fine tuning could be useful now as discussed earlier in the Q&A as well as uh as well um we see that there's another benefit other than performance to to uh do doing
(46:44) fine-tuning for models and that is the reducing the token count so because we do not need a very uh uh very elaborate prompt uh at the input side uh as well as the model is less ver bothos on the output end the model um so the model generates so generates and uses less tokens so the overall token computation is significantly reduced and that can result in significant token savings um as we we see here so that would be this all for this code lab let us move on to the second code lab which I am sharing my screen
(47:24) for second so give me a second [Music] um yes so I'm sh my screen for the second code lab and uh in this code lab we look at Google search grounding and how grounding as we discussed earlier in the Q&A as well can help you improve performance the first section of the Cod lab is an optional one of course where you can kind of try out grounding on Google search with the with the the Google AI Studio UI where you can um ask questions and enable grounding to get um more uh more upto-date and more accurate responses uh and you can also get
(48:09) citations so you can see where those answers came from as well as the uh see which part of the section um the response came from which which particular uh source and in the second part of the cab um we do this using API in a programmatic fashion and um here we uh basically ask um for example a question about a certain date when and where is Billy Al's next concept and we see that um it does not give you any specific dates because the model is trained up to a point of time and it does not have access to realtime information now with
(48:45) grounding enabled it gives you a specific itary of where um and when the concept will happen now another important aspect of the API uh is that it can provide you not only the response but also tell you the sources from where the grounding chunks chunks can tell you the sources from where the Google search um API provided you the response so and not only can It provide you the sources but you can also go further uh into it and see which part of the response uh it can be attributed to which which particular source and this can really
(49:19) help you um as we see in the next part of the cab uh it can really help you build this kind of um citation uh augmented response with where you know which parts of the response can be attributed to which specific um um sources um and the and after that in the Cod lab we learn about using tools together with the Google search um grounding tool as well so other tools for example the code generation tool so in this part we see that we ask it the question for example here and then we we provided the Google search tool and it
(49:57) provides you an upto-date accurate answer you by ground being grounded on the Google search um uh grounding uh Google search results but we go a step further where we give it an access to another tool the code execution tool which can actually um um write and execute code for you and we say okay take the results from what you got earlier here and U plot this as a c plot this as a cbor chart and we see here that it can generate a very nice chart for you I personally find this super super useful so yes that concludes our
(50:32) collab and off to you page for the pop quiz thank you amazing thank you so much anant and thank you to Mark McDonald also uh who is on our team who helped build and create all of the code Labs that you've been using over the last week so thank you uh thank you both so much um with that we are going to go into the last part of our uh of our course today which is the pop quiz um so for our pop quiz today you will be tested on all things fine-tuning and domain specific customization of large language models um starting with what is
(51:04) the primary goal of metm in the medical field is it a to replace doctors with AI systems for more efficient patient care is it B to develop AI models capable of diagnosing and treating diseases without human intervention is it C to improve health outcomes by making Advanced AI technology available to healthcare professionals or is it D to create a universal AI system system that can answer any medical question with 100% accuracy so grab uh your pen and paper or just kind of jot it down um somewhere or take note of it in your head uh what
(51:37) is the primary goal of metal m in the medical field I'm going to count down five 4 3 2 1 and it is C to improve health outcomes by making Advanced AI technology available to healthcare professionals um so keeping a human in the loop and making sure that we get the best quality Care um to folks question number two what is the significance of ensemble refinement in medp Palm V2 is it a um that it allows the model to learn from patient data B that it improves the model's ability to generate multiple choice questions C that it
(52:14) helps the model identify medical images or D that it enhances the model's reasoning and answer refinement by conditioning it on multiple generated reason Pathways um what is the significance of ensemble refinement I'm going to count down five 4 3 2 1 and the answer is D it enhances the model's reasoning and answer refinement by conditioning it on multiple generated reason Pathways question number three what is the Innovative approach used by cim to address security challenges um is it a developing a highly complex AI model
(52:51) with trillions of parameters for Superior performance B replacing human Su uh security analyst with fully autonomous AI agents C combining large language models authoritative data sources and a flexible Planning Network or D creating a global database of all known cyber threats for real-time threat detection um remember back to Scott and Chris's answers um and uh decide what is the Innovative approach used by secm I'm going to count down five 4 3 2 1 and the answer is C it combines large language models author ative data
(53:27) sources and a flexible Planning Network and as I mentioned it's uh it sounds really really cool to a distributed systems engineer excellent question number four how does secm address the challenge of limited publicly available security data is it by a collecting and storing sensitive user data for Central model training B by developing specialized llms trained on cyber security specific content and tasks C by relying solely on open source data for model training or D by generating Sy synthetic security data to augment um limited public data I'm
(54:01) going to count down five 4 3 2 one the answer is B by developing specialized llms trained on cyber security specific content and tasks um and with that thank you so much for everyone who has joined us today um really appreciate you your questions all of the activity that you've been uh that you've been doing on Discord um and can't wait to see you tomorrow for our last and final day of the kagle generative AI uh intensive course training hopefully you've learned something I certainly have um and we are really really grateful to have you as
(54:38) part of this broader learning family all over the world so thank you um see you tomorrow and get excited for our last and final day thank you everyone thank you bye