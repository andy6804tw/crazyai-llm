{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TSGiHPd49_t"
   },
   "source": [
    "# 使用 Streamlit 與 Ollama 建立聊天介面\n",
    "## 在 Google Colab 運行 Streamlit 並讓本機存取\n",
    "Google Colab 預設**無法直接執行 `streamlit run`**，因為 Colab 是一個 **雲端環境**，但我們可以透過 **localtunnel** 或 **ngrok** 來建立一個**可公開存取的網址**，讓本機能夠連上 Colab 內運行的 Streamlit 應用。\n",
    "\n",
    "### **步驟 1：安裝必要套件**\n",
    "在 **Colab** 內執行安裝 streamlit："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZXNYm9q55CX",
    "outputId": "cc457005-878f-40dc-be55-98f0cf168b4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW9pP4Lq5rjm"
   },
   "source": [
    "### **程式簡介**\n",
    "這支程式使用 **Streamlit** 建立一個簡單的 **單輪聊天介面**，並透過 **Ollama（類 OpenAI API）** 來處理對話請求。它的主要功能是：\n",
    "1. **使用者輸入訊息**，顯示在聊天框內。\n",
    "2. **程式將訊息傳送至 Ollama API（本機端 11434 連接埠）** 來獲取 AI 回應。\n",
    "3. **顯示 AI 回應**，並將對話內容保留在 `st.session_state` 中，讓使用者可以看到完整的對話紀錄。\n",
    "\n",
    "這是一個簡單的 **本機 AI 助手**，可以用來測試 **Ollama 所管理模型**，或作為更進階應用的基礎。這裡使用 **魔術指令** 在 Colab 中寫入程式：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9RtRjSK4fLF"
   },
   "outputs": [],
   "source": [
    "%%writefile basic.py\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# 設定 OpenAI API 金鑰與模型端點\n",
    "token = \"ollama\"\n",
    "endpoint = \"http://localhost:11434/v1/\"\n",
    "model_name = \"gemma2:9b\"\n",
    "\n",
    "client = OpenAI(base_url=endpoint, api_key=token)\n",
    "\n",
    "# 單輪對話初始化的 system prompt\n",
    "SYSTEM_PROMPT = {\"role\": \"system\", \"content\": \"你是一個有用的助手。且會根據使用者輸入的語言做回應。\"}\n",
    "\n",
    "# 初始化對話歷史，僅用於顯示（不保存上下文）\n",
    "if \"display_messages\" not in st.session_state:\n",
    "    st.session_state.display_messages = []\n",
    "\n",
    "# 顯示對話歷史\n",
    "for message in st.session_state.display_messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# 接收使用者輸入\n",
    "if user_input := st.chat_input(\"請輸入您的訊息...\"):\n",
    "    # 顯示使用者訊息\n",
    "    st.session_state.display_messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # 組合單輪對話訊息\n",
    "    messages = [SYSTEM_PROMPT, {\"role\": \"user\", \"content\": user_input}]\n",
    "\n",
    "    # 調用 OpenAI API 獲取回應\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model_name,\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "\n",
    "    # 獲取助理回應內容\n",
    "    assistant_response = response.choices[0].message.content\n",
    "\n",
    "    # 顯示助理回應\n",
    "    st.session_state.display_messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.markdown(assistant_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uVj7y3_Fs91"
   },
   "source": [
    "\n",
    "## 在 Colab 運行程式\n",
    "\n",
    "![](https://github.com/andy6804tw/crazyai-llm/blob/main/docs/2.LLM%E5%AF%A6%E6%88%B0%E6%87%89%E7%94%A8/images/img-ollama-streamlit-1.png)\n",
    "\n",
    "📌 **指令說明**\n",
    "\n",
    "- `!streamlit run basic.py &>./logs.txt &` → **在背景運行 Streamlit**，並將日誌輸出到 `logs.txt`\n",
    "- `npx --yes localtunnel --port 8501` → **開放公開網址**，讓本機存取 Colab 內的 Streamlit\n",
    "- `curl ipv4.icanhazip.com` → **顯示 Colab 機器的外部 IP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8OH5Z3pFtlk"
   },
   "outputs": [],
   "source": [
    "!streamlit run basic.py &>./logs.txt & npx --yes localtunnel --port 8501 & curl ipv4.icanhazip.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此命令會運行 **Streamlit 應用程式 (`basic.py`)**，並將輸出記錄到 `logs.txt`。同時，它使用 **localtunnel** 將應用程式在 **8501 連接埠** 上 **臨時公開到網際網路**。\n",
    "\n",
    "在 **Colab** 執行該命令後，應該會顯示類似以下的輸出內容：\n",
    "\n",
    "![](https://github.com/andy6804tw/crazyai-llm/blob/main/docs/2.LLM%E5%AF%A6%E6%88%B0%E6%87%89%E7%94%A8/images/img-ollama-streamlit-3.png)\n",
    "\n",
    "請**複製 IP 位址**（例如 **35.106.17.127**），然後**點擊產生的 URL**，即可進入應用程式的頁面。\n",
    "\n",
    "![](https://github.com/andy6804tw/crazyai-llm/blob/main/docs/2.LLM%E5%AF%A6%E6%88%B0%E6%87%89%E7%94%A8/images/img-ollama-streamlit-2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMkaP-ZkFyQ4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
