{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9004589-aa5f-4670-8a26-3d894f445547",
   "metadata": {},
   "source": [
    "## 利用 Ollama API 整合 OpenAI Python 函式庫\n",
    "Ollama 提供了與 OpenAI API 部分功能的相容，協助現有應用程式連接到 Ollama。這篇教學文件將引導你如何利用 OpenAI 函式庫與 Ollama API 整合，快速切換不同家的大型語言模型（LLM）服務。若要了解如何安裝 Ollama，請參考前一篇文章。利用 OpenAI 庫的優點在於，它相容市面上大多數 LLM 服務，只需替換 API URL，即可快速整合不同廠商的服務。\n",
    "\n",
    "## 1. 環境設定與客戶端初始化\n",
    "首先，我們需要安裝 OpenAI 函式庫（可透過 pip 安裝），接著透過下列程式碼初始化客戶端，並指定 API 伺服器的 URL 與金鑰。  \n",
    "以下範例中使用的是本機伺服器（例如：http://localhost:11434/v1/ ），金鑰雖必填，但此處實際上不會使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760d06ac-4a3d-4ca9-bc3f-4aae5832f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',  # 設定 API 伺服器的 URL，這裡使用本機端點\n",
    "    api_key='ollama',                      # API 金鑰（此例中為 'ollama'）\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c0fc5-a08f-487b-b74b-760ccb4b3040",
   "metadata": {},
   "source": [
    "## 2. Chat Completion API（對話生成）\n",
    "### 2.1 純文字聊天"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf0d63c-e117-47d7-8ee2-f8e6d36818ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "法國的首都是 **巴黎**。 🗼  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用 chat API 建立一個聊天請求\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',  # 設定角色為「使用者」\n",
    "            'content': '法國的首都在哪?',  # 提供要詢問的問題（提示詞）\n",
    "        }\n",
    "    ],\n",
    "    model='gemma2:9b',  # 指定模型\n",
    ")\n",
    "\n",
    "# 取得模型回應的內容\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6466da-6547-4808-aba6-db11b1ba296f",
   "metadata": {},
   "source": [
    "### 2.2 文字與影像混合輸入的聊天\n",
    "\n",
    "Ollama 的 API 除了支援純文字外，還可支援影像輸入。以下範例展示如何同時傳送文字與以 base64 編碼的影像資料：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "889433cd-5abe-4f11-ae2f-883bb90d808d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import base64\n",
    "\n",
    "# 讀取本機圖片並轉為 Base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# 圖片路徑\n",
    "image_path = \"./image.jpg\"\n",
    "base64_image = encode_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e72a309-523f-445a-81b0-630bf318c10c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可以在這個藍色圓圈內看到有一些暗棕色的文字，然而由於字體過小和顏色不明顯，因此很難辨別。\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"llama3.2-vision:11b\",  # 確保使用支援 Vision 的模型\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"這張圖片裡有什麼?\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "# 取得回應\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27014744-2c81-4346-a2f1-3af00a8d263a",
   "metadata": {},
   "source": [
    "## 3. Completion API(單次問答)\n",
    "若不需要多輪對話，也可以直接使用單次問答 API。以下範例以 prompt 提示「美國首都在哪裡?」並使用 `gemma2:9b` 模型取得提問結果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e43a83f6-b38a-449e-87a9-e950de6aeffa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "美國的首都是 **華盛頓哥倫比亞區**。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "completion = client.completions.create(\n",
    "    model=\"gemma2:9b\", # 指定模型\n",
    "    prompt=\"美國首都在哪裡?\", # 提供要詢問的問題（提示詞）\n",
    ")\n",
    "\n",
    "# 取得模型回應的內容\n",
    "print(completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca01740-b5dd-4899-8e95-4157aef2a032",
   "metadata": {},
   "source": [
    "## 4. 模型操作\n",
    "### 4.1 列出所有可用模型\n",
    "\n",
    "你可以使用下列程式碼列出目前 API 支援的所有模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "779c05cb-4703-4c42-b2ba-737898430346",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型 ID: llama3.2-vision:11b\n",
      "建立時間: 2025-02-19 12:21:06\n",
      "類型: model\n",
      "擁有者: library\n",
      "------------------------------\n",
      "模型 ID: gemma2:9b\n",
      "建立時間: 2025-02-19 12:08:58\n",
      "類型: model\n",
      "擁有者: library\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 取得可用模型列表\n",
    "list_completion = client.models.list()\n",
    "\n",
    "# 轉換 Unix 時間戳\n",
    "for model in list_completion.data:\n",
    "    readable_time = datetime.utcfromtimestamp(model.created).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"模型 ID: {model.id}\")\n",
    "    print(f\"建立時間: {readable_time}\")\n",
    "    print(f\"類型: {model.object}\")\n",
    "    print(f\"擁有者: {model.owned_by}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15200597-7d65-418f-a465-4cf9e078ff2a",
   "metadata": {},
   "source": [
    "### 4.2 取得特定模型資訊\n",
    "若想查詢某一特定模型的詳細資訊，可使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "068ed922-1ce8-409c-906e-932a53e10241",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型 ID: gemma2:9b\n",
      "建立時間: 2025-02-19 12:08:58\n",
      "類型: model\n",
      "擁有者: library\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "model = client.models.retrieve(\"gemma2:9b\")\n",
    "\n",
    "print(f\"模型 ID: {model.id}\")\n",
    "print(f\"建立時間: {datetime.utcfromtimestamp(model.created):%Y-%m-%d %H:%M:%S}\")\n",
    "print(f\"類型: {model.object}\")\n",
    "print(f\"擁有者: {model.owned_by}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b5193-1a09-4c25-870f-45776a428efd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. 產生 Embeddings\n",
    "\n",
    "另一項常用的功能是利用 embeddings 將句子轉換為向量表示，這對於語意相似度、文本分類等應用非常有用。需要先下載 all-minilm:22m 模型，這個模型是輕量級的 sentence embedding 模型。\n",
    "\n",
    "```sh\n",
    "ollama pull all-minilm:22m\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "以下範例使用 `all-minilm` 模型來為兩個句子生成 embeddings："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bb1b03e-45a5-4fd9-9d65-91e9799a727a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第一個句子的 Embedding（前 5 維）：\n",
      "[0.010048831, -0.0017536068, 0.05003938, 0.04698401, 0.055051647]\n",
      "\n",
      "第二個句子的 Embedding（前 5 維）：\n",
      "[-0.009840123, 0.060384717, 0.025232576, -0.0062687513, 0.07272164]\n"
     ]
    }
   ],
   "source": [
    "# 產生 Embeddings\n",
    "embeddings = client.embeddings.create(\n",
    "    model=\"all-minilm:22m\",  # 指定 embedding 模型\n",
    "    input=[\"why is the sky blue?\", \"why is the grass green?\"],  # 要轉換成向量的文本\n",
    ")\n",
    "\n",
    "# 取出第一個句子的向量\n",
    "embedding_1 = embeddings.data[0].embedding\n",
    "# 取出第二個句子的向量\n",
    "embedding_2 = embeddings.data[1].embedding\n",
    "\n",
    "# 只印出前 5 維，避免太長\n",
    "print(\"\\n第一個句子的 Embedding（前 5 維）：\")\n",
    "print(embedding_1[:5])\n",
    "\n",
    "print(\"\\n第二個句子的 Embedding（前 5 維）：\")\n",
    "print(embedding_2[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6912801-0b25-45a0-bb7b-57a388978525",
   "metadata": {},
   "source": [
    "### **預設使用的模型**\n",
    "`all-minilm` 是 **MiniLM**（Minimal Language Model）的變體，專門用來產生輕量級的 **句子向量（sentence embeddings）**。  \n",
    "這類模型主要來自 **Sentence-Transformers**，類似 **`all-MiniLM-L6-v2`** 這種模型，擅長計算句子之間的語意相似度，並且效能高、計算速度快。\n",
    "\n",
    "### **這段程式碼的作用**\n",
    "這行程式碼將兩個問題：\n",
    "- `\"why is the sky blue?\"`\n",
    "- `\"why is the grass green?\"`\n",
    "\n",
    "轉換成 **向量表示**，並且可以用來計算語意相似度，例如：\n",
    "- 如果兩個句子的意思很接近，則它們的向量之間的距離會很小（通常用 **餘弦相似度** 來計算）。\n",
    "- 這樣可以應用在 **搜尋引擎、文本分類、推薦系統、問答系統等**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "426a0861-884b-4d87-869f-710fa1cf18b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "兩個句子的語意相似度（Cosine Similarity）：0.4734\n"
     ]
    }
   ],
   "source": [
    "# 計算語意相似度（Cosine Similarity）\n",
    "import numpy as np\n",
    "\n",
    "cosine_similarity = np.dot(embedding_1, embedding_2) / (\n",
    "    np.linalg.norm(embedding_1) * np.linalg.norm(embedding_2)\n",
    ")\n",
    "\n",
    "print(f\"\\n兩個句子的語意相似度（Cosine Similarity）：{cosine_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b592f-954d-4a52-98a9-5625c7e8b1f4",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- [Ollama官方API文檔](https://github.com/ollama/ollama/blob/main/docs/api.md)\n",
    "- [Ollama官方相容Openai API文檔](https://github.com/ollama/ollama/blob/main/docs/openai.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f56290-f624-43ee-9972-d38e225e8de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
