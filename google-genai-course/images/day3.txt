DAY 3 Livestream - 5-Day Gen AI Intensive Course | Kaggle - YouTube
https://www.youtube.com/watch?v=g6MVIEzFTjY

Transcript:
(00:01) greetings everyone welcome back to our third day of the Kaggle Generative AI intensive course which is all about generative AI agents i'm Paige Bailey and I'm really excited to be here today to get to teach over a quarter of a million of you all around the world everything that you would ever need to know about generative AI and how you can incorporate it into your software engineering projects this discussion is going to be extremely extremely cool i'm very excited about some of the folks that we have on the call um and I can't
(00:29) wait to get started so just as a general reminder uh course overview this is a five-day intensive course taught between Google Cloud Google Labs Google DeepMind um uh kind of all of the all of the folks that we have working around uh around Google in the AI space have come together to build this course um and we're really excited to have you here today um this is day three which is all about AI agents and hopefully you've been learning to build sophisticated AI agents um uh over the last 24 hours um I want to thank our course moderators who
(01:04) have been tirelessly answering all of the questions on our discord as well as doing great things like uh sort of um testing out some of the course materials over time doing all of the logistics and behind the scenes work in order to actually make the Kaggle generative AI intensive course happen so a big virtual round of applause for everybody who is devoting their nights weekends um uh and and all of their energy and love into making this course a reality so thank you so much um and with that I'm going to turn it over to Anant for a quick
(01:35) curriculum overview of the white papers podcasts and materials that you've been learning from over the last 24 hours so take it away Anat thank you Paige hi everyone um so uh uh welcome to uh day three and you might have seen in the first couple of days that we learned about foundational models and how we can use prompt engineering along with day 2's embeddings and vector databases to provide the model with appropriate instruction and context for the job so in today's white paper we're diving deep into generative AI agents where we take
(02:10) what we have learned and show how LLMs can use the tech that we have discussed so far build upon it and use them dynamically um yeah so let's recap the main ideas of the white paper so first we read in the so we have you have two white papers right one is the first one being um the introduction to agents and the second one being slightly more advanced and in the first one we read what a uh that agents are basically AI applications that use models to achieve goals unlike standard ones they observe reason and act using tools and operating
(02:43) autonomously to or semi-autonomously to uh uh uh finish the objective that they were assigned then we also saw the their core components for example the model for instance Gemini for reasoning tools which include extensions functions and data stores for interacting with the external world and the orchestration layer which manage manages the thinking and action cycle using frameworks like react or chain of thought and more now then this was followed by the section looking closer at tools extensions um which is one of the uh tools let agents
(03:20) directly call APIs functions involve the model suggesting calls for client side execution giving developers like yourself more control and then finally data stores which ground access to external data often via a rag or um to keep uh responses grounded the papers also mentioned that uh as uh in enhancing agent performance through techniques like in context learning or fine-tuning but you'd find more about that in the day one's white paper so um in the second white paper which dives a bit more advanced there were a lot of
(03:54) topics which which were covered but uh what were the key points are things like agent ops and rigorous uh evaluation for agents uh agent ops talks about uh deploying the important practices for deploying agents in production you'll be seeing more about that on day five and but evaluation um talks agent evaluation talks about tracking metrics like goal completion analyzing the agents action trajectory assessing the final response and including human feedback where necessary and we also have a um service around this uh on Vort.ex which might be
(04:26) of interest to you um and then in the second white paper we also covered multi- aent systems which has been quite uh popular recently where specialized agents collaborate on complex tasks using patterns for example like hierarchical or collaborative setups to achieve the objectives agentic rag where agents define the retrieval process is a one of the keyh examples of where multi- aent systems could be very useful the white papers concluded by discussing agents in enterprise as assistants or for automation managed via platforms for
(04:59) instance um Vert.x AI's agent space and also an interesting new concept which is coming up which is um defining uh contracts for increasing the reliability of agents we also looked at some applications like co-scientist of multi- aent setup as well so that's the essence um now we'll explore more in the code labs later and the Q&A session which follows so off to you Paige take it over awesome and excellent uh let's move into our Q&A with all of the experts who have uh who have come online today to to be able to talk about the products that
(05:33) they're building and deploying all around Google Cloud um as well as in Google Labs and Google Deep Mind so I am overjoyed today to welcome Jacqueline Antonio Steven Julia Alan and Patrick onto the call um uh we have a lot of questions coming in from the audience so thank you for adding all of the all of the great questions on Discord um and with that I I am going to go ahead and get started so first question um welcome Stephen and Jacqueline i am a really devoted and excited user for both Notebook and Project Mariner um it's
(06:06) been really exciting to see all of the all of the great work that y'all have been doing to ship agents into production um so let's uh let's learn a little bit more stephen could you tell us a little bit about Notebook LM yeah sure um so uh some of you may have been experiencing uh Notebook LM through some of the uh audio overview podcasts you've been listening to as part of the programming here um we think of of Notebook LM as a as a tool for understanding things um so you give uh Notebook the documents that you're
(06:37) working with that are important to whatever project you're on and those can be docs or PDFs or slides or audio or YouTube links and number of other formats and once those documents have loaded into notebook it's like you're talking to an AI that's an expert in the information that that matters most to you that it's important to your project and that means it's it's personalized it's grounded in the in the facts in those documents um we have a really advanced citation system so that when the model answers a question based on
(07:07) your documents you can see the citation you can see the original passage that it used to answer the question you can click and read the original source material so you can fact check and and confirm that the answers are are viable ones and we've been adding tools to transform the information that you've uploaded into new formats um so audio overviews is kind of the most famous uh format we have so take your sources and suddenly you have a 12minute podcast conversation between two amazingly lifelike uh AI hosts uh you can create a
(07:39) briefing doc or a study guide and text um but we're actually adding uh we've just added a new feature that's been getting great reception we're really excited about it um I'm going to share it on on my screen here so you can see uh it's a feature called mind maps and uh basically it will take your sources and turn it into uh a a kind of visual representation of the concepts in whatever sources you've uploaded um so you can have you know your your in this case this is a American history textbook that I've uploaded and it's broken it up
(08:12) into all these categories but you could put your personal journals in here you could put your codebase in here like you will get a a really interesting visual representation and you can see these are the categories subcategories you can kind of like zoom into one of them and see you know kind of further topics and what's so powerful about mind maps and notebook LM is it's not just a a picture of the concepts in your documents every single one of these nodes in the mind map is actually a clickable query that
(08:44) you can then send to the model in notebook and you will get a a detailed overview of that particular topic with citations um all the all the amazing kind of tricks that notebook has up its sleeve so it's a really genuinely like new way to navigate through complex information and uh it it's now live in all notebookm for all notebook users this is so cool and I really wish I would have had something like this when going through university or just getting started with some of the code bases in Google 3 um I I think this is really
(09:16) really amazing at reducing the complexity for these really really uh kind of intimidating systems uh and it's great to know that that folks can test it out today um and speaking of navigating complex systems and doing useful things Jacqueline tell us a little bit about project mariner yeah absolutely so Project Mariner is a research prototype that's really exploring the future of human in agent interaction starting with your browser and what that means is that you can ask Mariner to complete a task for you and
(09:47) it will actually navigate the internet it will click through different websites it knows how to scroll how to type and it can actually get things done on your behalf so we launched it back in December um as a Chrome extension and it's been really interesting to just see what our trusted testers have been up to and watching Mariner think through the steps it should take to complete these complex tasks um on behalf of the user and actually get them through to the end of uh of accomplishing the things that they need done excellent i I have loved
(10:16) seeing all of the great demos for Project Mariner and I I also love that it's uh it's just a simple Chrome extension that you can just add to Google Chrome um and you're off to the races that is very very cool love the the focus on usability as well and uh I think we'll be hearing a little bit more about um uh Mariner's agentlike approach and some of the questions coming up soon um so everybody should stay tuned um next question this is for you Stephen um agents hold the promise of being collaborators or tools for thought which
(10:47) is I know a phrase that you um you have used and and uh throughout many of your books and throughout um much of your research so drawing on your experience with projects like notebookm or um other other projects that you're working on in labs what design principles are the most important for creating AI agents that successfully augment human capabilities um rather than just automating simple tasks and how do you balance agent autonomy with user control yeah balance is is such an important word here and it's a great question um I could talk
(11:20) about it for the rest of our time here actually so you know one of the core principles at notebook is the idea that um the the model is always grounded in the sources that you've given it right so that that's a defining thing that we we did from the beginning um so that you put in documents the model will answer based on the facts in those documents um that it has been specifically instructed to stick to those facts so if you upload that American history textbook and you ask a question about Taylor Swift it
(11:47) will politely decline to answer the question even though the model knows a lot about Taylor Swift right and so that focus is a huge part of the value proposition that that notebook presents however we want people to use notebook in a in a creative way in a brainstorming way we want notebook to help them think things that they wouldn't have otherwise thought about the documents that they have in front of them and so we get a lot of queries which are like hey based on the notes that I've uploaded here what's a
(12:14) adjacent related idea that I haven't thought of yet and we want the model to be able to do that but sometimes you know with our source grounding kind of instructions the model will come back and say like I cannot tell you about some other new idea because it is not mentioned in the sources and so we've spent a lot of time crafting the instructions to say listen you know the the basic framework should be these sources but you are allowed some creative latitude to explore kind of related ideas just don't go too far a
(12:42) field and it's it's kind of like building a a leash on the model where you can give it a little bit of room to move and navigate around the core kind of ground truth of the sources but the one thing I would recommend for folks who are interested in this kind of work is um every version of the model handles this kind of task slightly differently we found so we would get our system prompt to you know just the right amount of freedom and then we'd get we'd move on to a new version of Gemini we'd be really excited because there were all
(13:11) these capabilities but it would be maybe more faithful to the initial instructions and wouldn't would kind of decline to do those extra creative work and so we would have to rewrite the prompt um so every every generation of the models have slightly different interpretations of what its instructions really are and that's that's part of the art and maybe not the science of of this kind of work right now yeah I love the focus on collaboration in in notebook and being able to to kind of have a conversation with all of your source
(13:41) material um I I think that's a a great path for folks who are who are looking to to kind of incorporate more AI into their daily into their daily work um and also to learn a little bit and build intuition about how to interact with these systems so it's it's been very very cool to see thanks Paige yep excellent next question for Patrick um defining evaluating and debugging the behavior of autonomous or semiautonomous agents is super complex and I know this is something that a lot of our customers on Google Cloud have been um trying to
(14:14) think through over the last several months what new methodologies testing frameworks or observability tools are being developed or are needed to ensure that generative AI agents perform as intended remain aligned with user goals and can be reliably managed once deployed yeah that's a that's a lot there but um yeah I mean I think evaluations are probably like one of the most important things that you can do when you're deploying your agents into production uh and so you'll see a lot of that material covered in the companion
(14:42) paper on agents and you'll kind of hear it throughout the coursework as well just kind of the um reiterating how important evaluations are to kind of making sure that your production agents are doing what they're supposed to be doing now historically you know we've kind of had this concept of like the golden evaluation data set right where you have to manually define what are the requests going to look like and what are the responses going to look like uh you expect a certain number of tool calls they need to have happen in a certain
(15:09) order right uh and so defining this golden eval set and then testing it against your agent can actually be really brittle so while it might work right now as Stephen just pointed out as soon as you get Gemini 2.5 or Gemini 2.6 or 2.7 whatever the next model is it's just like all of those tests just kind of fall down and you can sort of think of this as kind of like you know unit tests is like if you're fundamentally changing you know the core of your your program all your unit tests are going to fail you have to rewrite your unit test
(15:38) right and so there's just kind of this back and forth back and forth that's going on with evaluations and while evaluations are important uh we realize it's a lot of toil for users to have to manage that with the pace of the new models coming out and things like that so one of the new innovations that we've been working on is this concept of uh testing scenarios instead of like you know strict golden uh data sets and the concept of the of a scenario is really more abstract uh versus just like an actual strict thing to follow so you
(16:06) know an easy way to think about this is imagine that you're building like a retail agent that does order status checking or something like this in the traditional sense you might say you know I need to check my order status you know what's your order number tool call tool response etc etc in a scenario-based environment you're basically just explaining to another AI agent that's going to be running the evaluations that you're saying like in general as you look at how this conversation has progressed we want to make sure that
(16:33) this task was complete that task being that an order status was checked we don't particularly care about which tools were called in what order we don't care about any small talk that happens in the middle we just care that the task itself was you know pretty much you know completed right and so that's really like the fundamental concept around scenarios it's much more abstract it's easier for sort of the average person to write a scenario than it is to write a golden evaluation data set and then you get a lot more um robustness out of your
(17:02) testing so even as the models change you still say you still have the the abstract concept that can apply to any of those variations of models that increase over time and a lot of this also allows you to do kind of like full autonomous testing you know constantly as new models are being released yeah I love that the the focus on outcomes for evals as opposed to trying to explicitly write out a recipe for each one i think that um that makes the process of writing evaluations even easier um than than some of the frameworks that we've
(17:33) already seen created and it also means that folks even outside of software engineering like in the product realm um or or project managers can even contribute to writing evals so this is this is very very cool to hear um next question um for for Patrick and for Julia um building robust AI agents requires effective tools use and grounding and reliable information so how are capabilities like function calling um and grounded search within Vert.
(18:03) Ex AI designed to work together to enable agents um to execute on these kind of multi-step tasks accurately and safely um and reliably i'll let Julia kick it off I guess sure um so the way that we see these things is these two capabilities really kind of work together and form the basis of a lot of the various agents that we see functioning today think about concepts like deep research um the co-scientist etc essentially we're allowing the agent to first retrieve some of that necessary information and then plan a sequence of actions and then execute on those
(18:38) actions based on on on function calls and uh while we spend a lot of time you know uh thinking about all of these different pieces I think one of the key things that u Stephen actually touched on earlier um is kind of that prompt and that is essential in the function calling side we spend most of our time actually debugging functions with customers because that's where often the the issues lie so really spending a lot of time tweaking and adjusting those kind of components and pieces and ensuring that that really is the end
(19:13) task that you're trying to solve is probably the most critical component to uh to to making those things work and I think this ties into the question that Patrick actually just answered as well that these scenarios and as like we like to call them oftentimes simulation tests will actually become more and more important and I had a researcher once describe it to me as up until now we were looking at multiple choice questions there was one right answer and now we're looking at an essay question where there are many different kind of
(19:43) right ways to get to the to kind of the scenario to to answer the question correctly and I think that's a really good way of of thinking about things and that's kind of the direction where we're heading in across the board of of both evaluations and w with function calling and that is the balance that you kind of have to strike now functions um need to be defined very crisply to execute on the task that you're trying to to solve to answer that specific essay question i love how uh how clear and how beautiful
(20:12) that analogy is and I'm I'm going to borrow it to like thank you for thank you for sharing is there anything you want to add yep yeah just a quick addition i mean and I love that analogy as well it's like one of my new favorite analogies to use thank you Julia um yeah just another comment on on function calling you know one of the interesting things that we've seen from like a research research perspective um as you know you spend a lot of time putting your prompts together and trying to get your tools to get called and function
(20:38) calling perspective um we see that like the more that you can actually get your your tools called or function calling happen happening during a multi-turn conversation especially a multi- aent conversation the fewer hallucinations that you will have and like the better and more grounded that that kind of conversation will be so you can imagine if you're just having sort of like a vanilla conversation without any tool calls the longer that conversation goes on the more propensity there is for hallucinations to start to occur because
(21:05) there's no any kind of tool calling you're just relying solely on model knowledge um but let's say if you're in a business environment an enterprise environment you really need to make sure that there are no hallucinations that means you need to start kind of trending towards more tool calls uh to make sure that you're grounded in you know whether it's Google search uh grounding or just you know API calls database calls behind the scenes uh so it's really important to have those tool calls and then one of the key points I think both Stephen and
(21:30) Julia called out is around the prompting aspect um inside of prompting you know we have this concept called fshot examples and I think it's really important for people to understand this concept of fshot uh Gemini really uh works awesomely out of the box but if you add few shot examples on top of that with tool calls you can really build a a really nice hardened system to ensure that your tools will be called in a specific order with lots of different you know parameters that are always going to happen the way that you want
(21:59) them to happen so I would say like prompting uh few shot examples and tool calling they all kind of go uh together hand inand to build a really nice production grade system yeah and just uh even as a person can get a much better output or much better response if you show them a few examples first large language models are the exact same way so as you're experimenting with Gemini and AI Studio and elsewhere um like make sure to include those few shot examples those those uh multiple examples of uh of what good looks like so the model can
(22:30) understand yeah I believe Jacqueline had something to add yeah I was going to say just one other thing I've seen come up on this topic in eval especially as we think about um moving towards essays not just multiple choice is defining what's good and that's becomes a lot fuzzier but it's really worth spending a lot of time to understand and like get in agreement with your team on like what is a good output and how are you grading those responses and I know Stephen uh firsthand that on the notebook team that's something that you've spent a lot
(22:55) of time is like how do you define what the output of a good audio overview is that's very different than just a right or wrong answer and that's something that's new in this era of uh AI I agents and these like more fuzzier outputs that we're now trying to evaluate against can I actually I have a funny story about this so we added to audio overviews um a few months ago this ability to join the conversation i think people have seen this as interactive mode um so you can be listening to the podcast but you can
(23:20) hit join and then you can ask a question and the host will then dynamically change the content of the podcast based on your question it's really amazing but when we first did it the when we rolled it out we found that the hosts were strangely irritated by being interrupted and so they had this whole attitude of like well fine i mean we were going to cover that later but I suppose and we literally had to do we talk about prompt we had to do what we called friendliness tuning to make the models to like to make the host just a little bit less
(23:53) like nasty to the to the user and we were all just like I can't believe this is our job what is what is even happening but from a user perspective that attention to detail matters so much and it comes in clear in product truth um for for all of the folks that are using Notebook LM and using the tools that uh that the folks on the call work on so thank you for for having that attention to detail um and doing the hard work to make sure that the experience lands in the way that uh that is most optimal for for human results
(24:25) excellent um so next question this is for Antonio um as generative AI agents move from experimental stages so some of the the tools like Project Mariner and Notebook LM which we've just been learning about towards broader deployment on platforms like GCP um what are the biggest hurdles for enterprise adoption are they technical are they ethical or are they related to managing these complex agent behaviors and integrations and Antonio you might be on mute i'm still smiling because I think that you just invented a term which is friendless
(25:03) uh tuning still that's what we do right that's that's exactly what we do uh and so I think that you already answered this this question because at the end of the day it's all about usability right so what how we satisfied user needs so uh you are on to something Stephen here well uh um seriously I think that one one aspect that we are seeing right now is that uh more and more pipelines are uh agent pipelines are the combination of multiple models uh and these are is becoming more more and more popular until very recently you were seeing
(25:37) probably one large model with a bunch of prompts now you're seeing multiple agents that are collaborating each other and um to to evaluate and to put this agents in in in production you basically are moving from singular to plural right so instead of having one single uh large model in production you have multiple agents that are collaborating so plurality of agents and is essential to put in production to have to define what what Jacqueline was saying like what's the definition of good the definition of a good here is a local definition of
(26:11) good for every single agent who is performing a specific action and also a global definition of good uh what how the end to end pipeline is is is behaving and so you need to have multiple metrics multiple definition of of goods for for taking into account accuracy efficiency bias prevention and also alignment right and and the topic is becoming more and more complex we have tools for doing this because of this plurality of of interactions awesome answer i I think the uh there are a lot of folks who are in enterprise
(26:47) companies today trying to put agents into production um so thank you for helping them kind of think through some of the some of the top of- mind items that they need to consider when deploying those agents um next question also for Antonio um uh how can we ensure that long-running agents stay aligned with their original goal and avoid drift um especially given the complexity and tokenheavy nature of uh LLM driven reasoning and tools use well this is I think this is a very fundamental question we are used to have for
(27:20) pipelines in in different sectors we are using to have like things like uh CI/CD uh before Patrick was mentioning uh the parallel here is the unit testing right and I think that what you need to have is to have uh ways to observe how the pipelines are working evolving over time um essentially connecting to what I was saying before uh if you think that you have multiple agents that are collaborating you need to have metric for this agents and magic for the wool pipeline itself uh tools that we are seeing used more and more have uh LLM as
(27:57) a judge for sure this is actually helping a lot having an external large model that is judging the behavior of every single agent and the bull pipeline itself we are seeing more and more usage of uh reinforcement learning uh very frequently paired with humans if these pipelines are actually supporting humans a fundamental question is what's the behavior of the pipeline when they are augmenting humans and what will have been the behavior of humans in this particular situation so reinforce learning is used with human evaluation
(28:28) human feedback but also more and more we are seeing things like uh uh in situations where you can reproduce an outcome so you have this thing is called rewards that are indeed some rewards that you can verify so code execution as well as situations where you have you can run an experiment and have a quantitive evaluation in all this situation reinforcement learning is working well because you can have a program programmatic improvement of things right uh and we are also seeing a usage of data uh that is evolving over time for
(29:05) doing back testing and so trying to fine-tune the agents uh for what will be the their behavior in the future where the future is already the past because you have this data used for for back testing this is a very complex topic but there are if you go into the uh white paper and the companion white paper you see many examples of this yeah and we'll be covering agent tops uh even more on day number five so thank you thank you so much Daring Beagle 34506 uh for our very first community question of the day wonderful next question for
(29:38) Alan um uh does Gemini support MCP uh so so I know this has been top of mind as an open standard for many many folks around the community um and I've personally really really enjoyed working uh working with MCP if so how can we integrate MCP with Gemini in an agent-driven flow and what are the benefits or drawbacks that this combination might offer uh totally the uh uh MCP standard uh has been growing in popularity a bunch especially in the last few weeks it's it's just like hockey sticking in popularity um but
(30:15) it's been around for several months and and we've been playing with it for a while uh we have some examples right now in Gemini examples repo and generative AI repo we've got uh several public things i'm sure we'll get some links to you um I think of MCP as just kind of like a thin shim around an API or like a universal SDK it's actually kind of fun to uh I've spent 20 years wiring APIs together and it's really fun to just like pop in servers from different companies and see them automatically working without a lot of wiring the
(30:49) discovery it is really convenient right um that convenience is going to continue I think to make it very popular um and any framework that's out there for building agents is going to support it if they don't already support it um and then the question of wrapping APIs into an MCP server and running that MCP server that's still kind of an open question in some ways uh you can do it pretty easily and then the question is does it have all of the parts and pieces that you need to really run this in production um we are working with Anthropic on
(31:28) trying to push forward what we would like to see in this standard um there were announcements I think it was last week or the week before where OOTH was announced and some other security uh additions um but you should absolutely be playing with this um I'm maybe a little old school and I'm not sure I would deploy it for a very sensitive production use case depending on your needs and how you deploy it today but uh it will absolutely be there uh and it's it's coming along so yeah sorry long-winded answer we support it we will
(32:00) probably continue to support it in lots of new and interesting ways um keep looking excellent and I love that uh it sounds like we're collaborating closely with Anthropic and exploring it for for our own products this is this is great news and if folks haven't already been experimenting with MCP make sure to check out those examples on GitHub as well as to check out some of these large hosted collections of MCP servers like Smithery or Composeio um cool so next question another community question um how do AI systems assess the reliability
(32:35) of real-time data from multiple sources resolve contradictions and how can they recognize and correct their own incorrect decisions um this is another community question from Johnv um and Julia and Jacqueline do you want to do you want to give some insights based on the products that you're working on sure i'm happy to take a a first quick pass here um so from our perspective or the way that I kind of think about this is that there's two pieces to this and we've touched on both of them already there's the evaluation side so as you're
(33:06) kind of testing and putting the agent out and then there is the kind of real time piece to to this question um I think we've talked about the evaluation scenario testing simulation and various other questions so I won't go into too much more detail on that but I think where it becomes interesting is in that kind of real-time structure and what we have seen quite a bit there is another agent that is specifically tuned to kind of collect all of the information evaluate it and merge it together into a response or to kind of
(33:40) decide whether or not this is the response that we kind of provide back to the end user so I think that that's kind of what we're going to start to see and to kind of use another analogy there you kind of have this team of folks that you are are are setting out to operate that are you know producing a specific response and then there is kind of a manager or someone that kind of makes that decision as to which response is then ultimately provided and I think that that's uh uh what what's what we're going to start seeing in in real time
(34:09) and that's where we tie back then also to the evaluation side because collecting those different examples figuring out where you know that evaluation agent was potentially wrong is going to be key to kind of continuing to then improve the system as as these different components work together and you can think about it much as like a team uh that's working of humans that are also working together in in in some of that sense so you kind of you know move forward you you you put some things out there you gather feedback and then
(34:37) you collect and and and adjust as as you continue to move forward yeah i think um just like adding on to that the way I also like to think about it is either like a team of agents or just multiple steps in your AI system that you're building where maybe the first step is you generate you know five candidate responses and then you can pass it to another prompt which says evaluate which of these five prompts are or five responses are the best and select the best one then you can move on to the next step which is okay really reread
(35:03) this response is it accurate is it fun is it like is it good however you've defined what good is if so great that can be your output if not okay let's go back to the beginning and this role of like a critique and a critique loop becomes really important so that you can always go back and start again even in these real-time scenarios it does add latency so these are things to consider as well and cost but it's certainly like having these loops that can go back and self-correct even in real time become incredibly important um and the way you
(35:30) prompt them also becomes incredibly important so a lot of just you know prompt engineering a little bit of magic a lot of trying different things uh in order to to be able to do that effectively awesome answers i love uh I love this attention to detail and care for building these uh for building these agent systems and I I think that there are um there used to not be very many frameworks or perspectives on it and now kind of the the people who have been doing it actively in production are are able to get out those insights into the
(35:59) world so it's been great to see how these best practices have been evolving um next question for for Julian for Allan what fundamental limitations and risks might persist for highly autonomous AI agents capable of creating their own tools um and how can these be safely managed so instead of humans defining the tools um the agents are able to to kind of create and design their own tools so I think we're still in the very early stages of this to a certain degree um and I think you'll see a lot of these operate with human in the loop um
(36:34) moments um you can kind of think about this in the in terms of like a capability like deep research you send it off to go and do something for you for a period of time and then it comes back to you with a response and with a with a structure and I think you'll we'll start to see more of these type of systems and we've actually very cleanly defined that in um in the a uh AI agents uh page on Google Cloud there's actually two different agents that we kind of uh use to talk about things the classical kind of chat agent that we're kind of
(37:04) used to that we've been interacting with and then what we've also defined as a as a background agent and that background agent tends to kind of operate in in the background behind system often potentially in kind of like a retail setting or in a supply chain setting or or something along those lines and I think we'll see a lot more of those in the future and I think that's where this specific where a lot of these specific use cases become very interesting um because they can go off and kind of do thing but there's always this kind of
(37:33) human that is a specialized individual that comes to check that back uh uh before kind of any any task is actually executed and I think that's kind of the the safety structure that is is something that's in place right now and that I I I continue to suggest to customers that are thinking about these kind of use cases um to keep in mind as they as they go about them excellent ellen is there anything you'd like to add yeah uh it's already happening agents are writing code writing tools executing those tools um there is an opportunity
(38:06) to have control over the code and tools that they write and write it down and then have a human in the loop audit that and when the agent is submitting a PR as opposed to just running things that are ephemeral um you end up with a lot more visibility and control i think that that's going to be a pattern that we're going to see more of soon yeah and I love turning on the code execution flag for the Gemini APIs where you give Gemini the ability to write run and then even recursively fix code if it encounters errors um oftentimes like I I
(38:38) might have a Python task but I don't necessarily know what library to import uh and having it be able to to kind of go through that guesswork for me um is is pretty uh is pretty awesome excellent um thank you so much for the for the community questions Simone um next question um what are the key challenges in deploying real-time AI um agents in production environments um including things like response time API costs and accuracy how do AI agents handle conflicting instructions or ambiguous queries from users and are
(39:13) there techniques to improve reasoning in such cases so I uh thank you for the great question Assad um I I do think that we've touched on this a number of times uh throughout the discussion today and and it feels like there's always some trade-off between balancing um balancing response time the costs for the models and the accuracy um at Google we've been investing significantly in trying to have really really powerful models um while also keeping the GPU footprint low so I'm not sure if folks saw the recent Gemma 3 release but um
(39:44) we're able to have pretty impressive performance on benchmarks while still just only requiring a single H100 um as opposed to 32 which is some what some of our um similar competitors might require um so I I think there there are often these trade-offs that you have to think about um uh pretty specifically i would love to open this up though to all of the folks who are working on real-time agents and models um in production would anybody like to add something to help answer Assad's question yeah I'll I'll jump in real quick on this uh actually
(40:16) so one of the things I think it's important for everyone to understand about like real-time agents is that we've we've moved into a new fundamental architecture from what we had before so one of the things you know if you think about like before you saw things like project Astra and realtime birectional streaming what we used to work in was what we call a turnbased paradigm there was a request you waited and then there was a response and even if that request included a tool call and another tool call there was a response but this was
(40:40) what we called a blocking loop right that that kind of happened the way it happened when we move into this new kind of you know architecture paradigm of real-time birectional streaming we're moving away from that turn-based paradigm and we're we're moving into like a full birectional event stream that means I am always talking and you are always listening and someone else is always talking and someone else is always listening and there are events that are just coming from everywhere at all times and those events are
(41:05) timestamped and those events are IDed to be able to match up to each other but this is what allows us to build these like really magical experiences so if you've tried you know streaming with Gemini sharing your screen and talking and doing all these things that is a quite chaotic event stream that's happening behind the scenes of lots of things coming in and out but there's no concept of a turn really anymore maybe you could draw an imaginary box around a set of events and say this was a turn and that was a turn but it's it's a
(41:30) really different way of thinking when it comes to like designing these agents designing the evaluations for these agents and really understanding fundamentally how they're going to work you know what happens if I ask a question while a tool call is happening before the response comes back from that tool call do I get a hallucinated response because the grounding hasn't come back you know those types of things need to be in consideration now because we're in this new sort of architecture uh of real-time streaming i love it it's
(41:56) like a playground for distributed systems humans like I I I love I love these complex uh these complex interactions jacqueline did you want to add something yeah I was going to add something to the second part of what you had asked which is um how do we handle ambiguous requests from users and I think there's no like one easy answer i think that this is once again like defining what a good experience is in your product in some cases you might want the agent to just assume things so you can get the task done and in some
(42:22) cases maybe you can like recall back to the memory and like see if the missing piece was mentioned previously and pull that in on other times you might want to actually ask the user what did you mean by this like hey you wanted a dinner reservation for 2 at 8:00 p.m uh did you have a specific location in mind or we could just default to knowing where the user was and suggest a bunch of options that are close by to where they are so I think this is where a lot of that product thinking will come in also to understand when do you assume when do
(42:48) you want to prompt the user again when do you want to come with a bunch of suggestions and let them choose from one of those options um so lots of uh yeah lots of options on the table but I think you kind of need to understand what's the best path for your particular product that you're building too yep and having that empathy for users and and really understanding their goals and their motivations that is that is definitely something that is uh appreciated in this brave new AI world um Antonio did you want to add something
(43:13) well very very quickly again I'm thinking of what Stephen was saying to earlier uh the way in which we humans uh work is we are uh we don't have we don't follow strict rules or terms right this is more natural more more closer to to how we interact uh even in this discussion there are multiple flows of of discussion that are not prepared in advance so there is not a single cycle of you you ask then someone is answering and so on and so forth but it's more natural it's more close to to humans more friendly absolutely we're doing it
(43:48) live we're doing it live all the time excellent next question um this is from Shavelin um Alan what are the security and privacy considerations that you think about when integrating APIs like Gemini into applications that might handle sensitive user data so especially production systems yeah um this is a wonderful thing to think about when you're building anything uh this is not just about agents or just about generative AI if you're going to take inputs you need to know where you're going to write down those inputs uh if
(44:25) you're going to process them in subsystems and hand off to other APIs and dependencies downstream you're in charge of all of the edges of the graph of code execution that you are building and if you own it then you're really in charge and if you don't own it then you're taking dependencies on somebody else and you need to read those terms of services and those privacy documents to know what's going to be written down so like in my case Google Cloud uh we we're very clear about we're not going to write down and train on any of your
(44:54) prompts and stuff um that's a big component of this is just owning those edges uh I always say agent ops is is really you don't forget about DevOps right like all of the traditional software best practices still apply and those tools that your agents are using are just as much in scope as the prompt that you're thinking about because uh user information can downstream itself into those prompts um that's a vague handwavy answer um let me give you a quick tip um if you feel like uh if your use case allows you to you
(45:31) can transform the user input into a rubric or an ontology or whatever on the fly early on in a pipeline and then you can be a little bit more confident that uh the private user information is isolated to that early stage and downstream from that is just your structured data that is a interpretation that's not a perfect quick tip but that might help awesome thank you so much for for giving that guidance and uh thank you to all of our wonderful speakers today please everyone give a virtual round of applause i have learned so much
(46:07) through this discussion um and can't wait to try out some of the things that that y'all recommended um so thank you so much to everybody for for coming um for coming here today for uh for teaching all of the you know quarter of a million of developers that we have around the world all about notebookm and project mariner and all of the great work that's coming out of Google cloud um really loved having you here today um and uh with that I'm going to turn it over to Anat to give us a little bit of insight about the code labs thank you
(46:40) Paige so um in interest of time since we had a very interesting discussion I will share my screen now I'll be quick with our code labs um so uh the first code lab we talked a lot about function calling uh and the first code lab looks into basically building um a chat interface where you can uh interact with your local database with natural language questions of course it's a PI database so um these apply more security considerations when you use it in production but yeah so going ahead into the first section of the code
(47:14) lab this is where we kind of create a local database a SQLite in-memory database to play around with we populate it with data so we populated with the products the staff which can sell the products and orders placed by customers and we insert some uh so we create the schemas and we add some data uh synthetic data into the table and and Anant are are you sharing your screen uh just uh just checking yes I am sharing my screen beautiful we can see the code now excellent thank you okay um so um yes uh so let me just start over um
(47:57) so the first part create talks about creating a local database we populated with some synthetic data uh um for three three different tables for products customers who bought the products as well as stuff which sells the products uh then we define basically now that we have created the data database uh and populated it we defined the database functions which the model especially Gemini 2.
(48:23) 0's and O's um native uh function calling capabilities would be using to interact with the database so we define functions around listing the the tables to see what tables are present um describing the tables and the schema as well as uh of the various fields the data types of the various fields executing queries for example select all um etc and now that we've defined the function cause through which the model can interact with the database we go into um inter uh implementing this together with Gemini and um um this this diagram here defines kind of the
(48:57) function flow um of how this um workflow works where user um kind of we define the user kind of provides a natural language input to Gemini it calls unnecessary functions get the response back and uses the response to provide a natural language answer to the user's question so here we uh initialize the Gemini 2.
(49:21) 0 you know API with the various tools and the instructions um for the role of the chat uh chatbot and we see here that uh when the user asks for a question like what is the cheapest product Gemini executes the logical figures out the logical sequence of function calls which you should do provides it the necessary data gets the response back um provides you the answer um similarly for other queries as well and what is very very interesting uh Something you can do is you can inspect the conversation which means you can see the reasoning steps that were used from
(49:54) how it mapped from the natural language query to the function calls and the the output and how the model reasoned that it needs another function call etc all the way till it arrived at the answer of your questions now another point uh in this collab which is new with Gemini 2.0 is that um um you you can use the live stream uh sorry live API um Gemini 2.
(50:16) 0 live API um to um actually do compositional function calling which basically means that um it not only um does the function calls it also generates the the code for that function call and to arrive and after that function call to arrive at the answer which the user is looking for one uh example which I really like in this collab is um um give me a second yeah towards the end um yes um there is an example where you ask to figure out um figure out the number of orders that are made by each of the staff and then generate and run
(50:55) some code to plot this as a Python seabbond chart so all of this not only interacts not only interacts with the tools and the functions provided to it but also writes code to um like plot the necessary plots as as instructed and this can be done in real time um right now in the example is with text but you can do this with uh voice audio input as well um moving on to the second code lab um in interest of time this code lab is quite big and has a lot on lang graph so I'll be very quick but this talks about building a barista bot where you can
(51:29) kind of have a barista bot uh order uh like order coffee and other drinks for you as well as play um provide the various functionalities the user can interact with in order to fulfill the order so um the the first part of the collab basically talks about defining the core instructions which you would like the bot to follow and provided the various uh tool um um instructions for example uh you can use the place order to place order uh get order add to order confirm order all of the things which a barista chatbot would require then you
(52:06) go all the way from single turn chat bots all the way uh where you have just a chatbot answering you to multi-turn ones where you have a back and forth conversation and then um all the way um till the end where you kind of provided the menu which the barista bot can um can dynamically retrieve from a function call um and um and in the very end we see that um all of this is all wired together with the nodes uh and the edges in the langraph structure which um to provide a system which uh which is dynamic where the you the human can
(52:42) interact with the chatbot the chatbot based on the request and the context so far what the the actions human has taken um place uses various tools and uh and retrieves the necessary um uh information and interacts with uh gives the response back to the human human can gives further instructions all the way until a terminal condition where human says good uh is reached and where the process ends and in a real-time system maybe your coffee is ordered so thank you that'll be all and off to you Paige for the pop quiz thank you amazing thank
(53:19) you so much for the walkthrough of the code labs and thank you to Mark McDonald for for creating them behind the scenes mark is one of our colleagues based in Australia so if folks are are based uh around Australia um you have uh you have teams around the world that are that are working hard to bring this generative AI course to you um so I'm going to to start now with the pop quiz um uh and pull up my screen um so for our pop quizz's first question um uh this feels very existential what is a generative AI agent is it A a type of
(53:56) machine learning model B an application that can observe the world and act upon it using tools C an LLM that can only be used for text generation or D a type of hardware for training LLMs hopefully folks were paying attention today in the Q&A section as well as in the white papers and code labs um and I'm going to count down five four three two one make sure to note your answer um a generative AI agent is B an application that can observe the world and act upon it using tools question number two what is the
(54:29) primary function of the orchestration layer in a generative AI agent um is it A to generate creative text and images B to manage the agents internal reasoning and planning process c to interact with users through a conversational interface or d to store and retrieve data from external sources um so everybody jot down your answer um using either you know pen and paper or just kind of um thinking about what your answer might be i'm going to count down 5 4 3 2 1 and the primary function of the orchestration layer is to manage the
(55:05) agents internal and reasoning and planning process question number three in what scenario might the developer choose to use functions over extensions and a generative AI agent um is it when the agent needs to make multiple calls in an API uh and a sequence is it when the API requires real-time interaction with the agent um is it C when the developer needs more control over the data flow and API execution or is it D when the API is easily accessible by the agents infrastructure hopefully folks were paying attention to Julia and Patrick
(55:40) and Allen sections um when might a developer choose to use functions over extensions um and the correct answer is C when the developer needs more control over the data flow and API execution um and hopefully folks are playing around with um function calling with things like MCP servers i'm really excited to see what you all build question number four what is the purpose of data stores in a generative AI agent is it A to store the agents configuration settings and parameters is it B to provide the agent with access to
(56:16) dynamic and up-to-date information is it C to execute complex calculations and data transformations or is it D to monitor and evaluate the agents performance over time um counting down five 4 3 2 1 it is B to provide the agent with access to dynamic and upto-date information question number five which of the following is not a characteristic typically associated with generative AI agents is it A that they can create new content such as text images or music b that they can learn from large data sets to identify
(56:51) patterns and generate similar content c that they possess inherent consciousness and understanding of the content that they create or is a D that they can be used for tasks like translation summarization and content creation um so remember this is not a characteristic typically associated with generative AI agents i'm going to count down five 4 3 2 1 um sometimes I feel like we should have Jeopardy music but C um agents do not possess inherent consciousness and understanding of the content that they create um six uh what is the mixture of
(57:30) experts uh or mixture of agent experts approach in agent development is it A combining multiple language models into a single agent um B using a variety of tools to enhance agent capabilities C combining specialized agents each excelling in a particular domain or task or D integrating different reasoning frameworks within the orchestration layer um think very very hard um remember back to the white papers and all of the the conversations that we've had today 5 4 3 2 1 it is C combining specialized agents each s excelling in a
(58:06) particular domain or task um and with that thank you so much for joining us here today we are overjoyed to have all of you um uh kind of here and learning all about generative AI and how to use it in your own projects and we can't wait to see you tomorrow um where we'll be covering even more topics uh including white papers code labs and more so thank you so much um and see you later