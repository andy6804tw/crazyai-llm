{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TSGiHPd49_t"
   },
   "source": [
    "# ä½¿ç”¨ Streamlit èˆ‡ Ollama å»ºç«‹èŠå¤©ä»‹é¢\n",
    "## åœ¨ Google Colab é‹è¡Œ Streamlit ä¸¦è®“æœ¬æ©Ÿå­˜å–\n",
    "Google Colab é è¨­**ç„¡æ³•ç›´æ¥åŸ·è¡Œ `streamlit run`**ï¼Œå› ç‚º Colab æ˜¯ä¸€å€‹ **é›²ç«¯ç’°å¢ƒ**ï¼Œä½†æˆ‘å€‘å¯ä»¥é€é **localtunnel** æˆ– **ngrok** ä¾†å»ºç«‹ä¸€å€‹**å¯å…¬é–‹å­˜å–çš„ç¶²å€**ï¼Œè®“æœ¬æ©Ÿèƒ½å¤ é€£ä¸Š Colab å…§é‹è¡Œçš„ Streamlit æ‡‰ç”¨ã€‚\n",
    "\n",
    "### **æ­¥é©Ÿ 1ï¼šå®‰è£å¿…è¦å¥—ä»¶**\n",
    "åœ¨ **Colab** å…§åŸ·è¡Œå®‰è£ streamlitï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZXNYm9q55CX",
    "outputId": "cc457005-878f-40dc-be55-98f0cf168b4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW9pP4Lq5rjm"
   },
   "source": [
    "### **ç¨‹å¼ç°¡ä»‹**\n",
    "é€™æ”¯ç¨‹å¼ä½¿ç”¨ **Streamlit** å»ºç«‹ä¸€å€‹ç°¡å–®çš„ **å–®è¼ªèŠå¤©ä»‹é¢**ï¼Œä¸¦é€é **Ollamaï¼ˆé¡ OpenAI APIï¼‰** ä¾†è™•ç†å°è©±è«‹æ±‚ã€‚å®ƒçš„ä¸»è¦åŠŸèƒ½æ˜¯ï¼š\n",
    "1. **ä½¿ç”¨è€…è¼¸å…¥è¨Šæ¯**ï¼Œé¡¯ç¤ºåœ¨èŠå¤©æ¡†å…§ã€‚\n",
    "2. **ç¨‹å¼å°‡è¨Šæ¯å‚³é€è‡³ Ollama APIï¼ˆæœ¬æ©Ÿç«¯ 11434 é€£æ¥åŸ ï¼‰** ä¾†ç²å– AI å›æ‡‰ã€‚\n",
    "3. **é¡¯ç¤º AI å›æ‡‰**ï¼Œä¸¦å°‡å°è©±å…§å®¹ä¿ç•™åœ¨ `st.session_state` ä¸­ï¼Œè®“ä½¿ç”¨è€…å¯ä»¥çœ‹åˆ°å®Œæ•´çš„å°è©±ç´€éŒ„ã€‚\n",
    "\n",
    "é€™æ˜¯ä¸€å€‹ç°¡å–®çš„ **æœ¬æ©Ÿ AI åŠ©æ‰‹**ï¼Œå¯ä»¥ç”¨ä¾†æ¸¬è©¦ **Ollama æ‰€ç®¡ç†æ¨¡å‹**ï¼Œæˆ–ä½œç‚ºæ›´é€²éšæ‡‰ç”¨çš„åŸºç¤ã€‚é€™è£¡ä½¿ç”¨ **é­”è¡“æŒ‡ä»¤** åœ¨ Colab ä¸­å¯«å…¥ç¨‹å¼ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9RtRjSK4fLF"
   },
   "outputs": [],
   "source": [
    "%%writefile basic.py\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "\n",
    "# è¨­å®š OpenAI API é‡‘é‘°èˆ‡æ¨¡å‹ç«¯é»\n",
    "token = \"ollama\"\n",
    "endpoint = \"http://localhost:11434/v1/\"\n",
    "model_name = \"gemma2:9b\"\n",
    "\n",
    "client = OpenAI(base_url=endpoint, api_key=token)\n",
    "\n",
    "# å–®è¼ªå°è©±åˆå§‹åŒ–çš„ system prompt\n",
    "SYSTEM_PROMPT = {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€å€‹æœ‰ç”¨çš„åŠ©æ‰‹ã€‚ä¸”æœƒæ ¹æ“šä½¿ç”¨è€…è¼¸å…¥çš„èªè¨€åšå›æ‡‰ã€‚\"}\n",
    "\n",
    "# åˆå§‹åŒ–å°è©±æ­·å²ï¼Œåƒ…ç”¨æ–¼é¡¯ç¤ºï¼ˆä¸ä¿å­˜ä¸Šä¸‹æ–‡ï¼‰\n",
    "if \"display_messages\" not in st.session_state:\n",
    "    st.session_state.display_messages = []\n",
    "\n",
    "# é¡¯ç¤ºå°è©±æ­·å²\n",
    "for message in st.session_state.display_messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# æ¥æ”¶ä½¿ç”¨è€…è¼¸å…¥\n",
    "if user_input := st.chat_input(\"è«‹è¼¸å…¥æ‚¨çš„è¨Šæ¯...\"):\n",
    "    # é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯\n",
    "    st.session_state.display_messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_input)\n",
    "\n",
    "    # çµ„åˆå–®è¼ªå°è©±è¨Šæ¯\n",
    "    messages = [SYSTEM_PROMPT, {\"role\": \"user\", \"content\": user_input}]\n",
    "\n",
    "    # èª¿ç”¨ OpenAI API ç²å–å›æ‡‰\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model_name,\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "\n",
    "    # ç²å–åŠ©ç†å›æ‡‰å…§å®¹\n",
    "    assistant_response = response.choices[0].message.content\n",
    "\n",
    "    # é¡¯ç¤ºåŠ©ç†å›æ‡‰\n",
    "    st.session_state.display_messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.markdown(assistant_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uVj7y3_Fs91"
   },
   "source": [
    "\n",
    "## åœ¨ Colab é‹è¡Œç¨‹å¼\n",
    "\n",
    "![](https://github.com/andy6804tw/crazyai-llm/blob/main/docs/2.LLM%E5%AF%A6%E6%88%B0%E6%87%89%E7%94%A8/images/img-ollama-streamlit-1.png)\n",
    "\n",
    "ğŸ“Œ **æŒ‡ä»¤èªªæ˜**\n",
    "\n",
    "- `!streamlit run basic.py &>./logs.txt &` â†’ **åœ¨èƒŒæ™¯é‹è¡Œ Streamlit**ï¼Œä¸¦å°‡æ—¥èªŒè¼¸å‡ºåˆ° `logs.txt`\n",
    "- `npx --yes localtunnel --port 8501` â†’ **é–‹æ”¾å…¬é–‹ç¶²å€**ï¼Œè®“æœ¬æ©Ÿå­˜å– Colab å…§çš„ Streamlit\n",
    "- `curl ipv4.icanhazip.com` â†’ **é¡¯ç¤º Colab æ©Ÿå™¨çš„å¤–éƒ¨ IP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8OH5Z3pFtlk"
   },
   "outputs": [],
   "source": [
    "!streamlit run basic.py &>./logs.txt & npx --yes localtunnel --port 8501 & curl ipv4.icanhazip.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ­¤å‘½ä»¤æœƒé‹è¡Œ **Streamlit æ‡‰ç”¨ç¨‹å¼ (`basic.py`)**ï¼Œä¸¦å°‡è¼¸å‡ºè¨˜éŒ„åˆ° `logs.txt`ã€‚åŒæ™‚ï¼Œå®ƒä½¿ç”¨ **localtunnel** å°‡æ‡‰ç”¨ç¨‹å¼åœ¨ **8501 é€£æ¥åŸ ** ä¸Š **è‡¨æ™‚å…¬é–‹åˆ°ç¶²éš›ç¶²è·¯**ã€‚\n",
    "\n",
    "åœ¨ **Colab** åŸ·è¡Œè©²å‘½ä»¤å¾Œï¼Œæ‡‰è©²æœƒé¡¯ç¤ºé¡ä¼¼ä»¥ä¸‹çš„è¼¸å‡ºå…§å®¹ï¼š\n",
    "\n",
    "![](https://github.com/andy6804tw/crazyai-llm/blob/main/docs/2.LLM%E5%AF%A6%E6%88%B0%E6%87%89%E7%94%A8/images/img-ollama-streamlit-3.png)\n",
    "\n",
    "è«‹**è¤‡è£½ IP ä½å€**ï¼ˆä¾‹å¦‚ **35.106.17.127**ï¼‰ï¼Œç„¶å¾Œ**é»æ“Šç”¢ç”Ÿçš„ URL**ï¼Œå³å¯é€²å…¥æ‡‰ç”¨ç¨‹å¼çš„é é¢ã€‚\n",
    "\n",
    "![](https://github.com/andy6804tw/crazyai-llm/blob/main/docs/2.LLM%E5%AF%A6%E6%88%B0%E6%87%89%E7%94%A8/images/img-ollama-streamlit-2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMkaP-ZkFyQ4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
