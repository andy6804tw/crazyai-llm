# Day 1: 大型語言模型基礎與提示工程
本日聚焦在兩大主題。透過這兩個單元的學習，第一天課程讓你建立起生成式 AI 的基礎知識，並開始實際操作提示語工程的技術，為後續更深入的學習打下堅實的基礎。

1. **基礎大型語言模型與文本生成**  
2. **提示工程**


### 單元一：基礎大型語言模型與文字生成

- **🎙️ Podcast 聆聽**  
  請先聆聽本單元的 [Podcast 摘要](https://www.youtube.com/watch?v=Na3O4Pkbp-U&list=PLqFaTIg4myu_yKJpvF8WE2JfaG5kGuvoE&index=1)，藉此快速掌握大型語言模型的基礎概念與文字生成的原理。

- **📄 白皮書閱讀**  
  為了補充 Podcast 內容，閱讀「[Foundational Large Language Models & Text Generation](https://www.kaggle.com/whitepaper-foundational-llm-and-text-generation)」白皮書，深入了解相關技術與應用案例。

### 單元二：Prompt 工程

- **🎙️ Podcast 聆聽**  
  聆聽此單元的 [Podcast 摘要](https://www.youtube.com/watch?v=CFtX0ZyLSAY&list=PLqFaTIg4myu_yKJpvF8WE2JfaG5kGuvoE&index=3)，了解如何設計與優化提示語（prompt）的基本原則與策略。

- **📄 白皮書閱讀**  
  閱讀「[Prompt Engineering](https://www.kaggle.com/whitepaper-prompt-engineering)」白皮書，以獲得更多關於提示語設計的細節與實際操作指引。

- **💻 Kaggle 實作練習**  
    完成以下兩個實作練習，進一步驗收所學：
    1. [提示基礎](https://www.kaggle.com/code/markishere/day-1-prompting)：練習基本的提示語設計與運用。
    2. [評估與結構化資料](https://www.kaggle.com/code/markishere/day-1-evaluation-and-structured-output)：學習如何評估提示語效果及處理結構化數據。

!!! info "本日學習重點"

    今天的課程主要讓你瞭解以下內容：

    - **大型語言模型演進：**  
      探索從 Transformer 到 fine-tuning、推論加速等各種技術的演進過程，理解模型如何從原始架構逐步進化並達到現在的效能。

    - **提示工程技巧：**  
      學習如何設計並優化提示，使得模型能夠更精確、高效地回應各種任務，包括文本生成與問答任務。  
      - **第一個 codelab** 會引導你如何使用 Gemini 2.0 API，並介紹多種提示技巧及各參數對回應的影響。  
      - **第二個 codelab** 則會教你如何利用自動評分器與結構化輸出來評估模型回應的品質。

    透過今天的學習，你不僅會對大型語言模型的基本運作有更深入的理解，還能掌握如何透過提示工程達到最佳的互動效果，並學習如何有效評估模型輸出的品質。



## Day 1 直播精華整理

目前生成式 AI 正處於爆發發展的時代，不僅模型架構與運算能力日新月異，提示工程也從早期的摸索轉向更有系統化的設計。在這五天的密集課程中，專家們從 Google、Kaggle 與 DeepMind 帶來了許多前瞻觀點與實戰經驗，今天的直播 Q&A 更是直擊技術核心與未來挑戰。以下依序整理出直播中的主要問答重點。

---

### Q1：AI Studio 的定位與能力  
**問題內容：**  
介紹 [AI Studio](ai.dev) 為開發者帶來哪些功能，以及如何連結 Google DeepMind 的最新研究與 Google Cloud 工具？

**專家觀點：**  
- **Logan** 表示 AI Studio 是快速接入最新 Gemini 模型的捷徑，能夠讓開發者直接測試模型功能，並透過一鍵取得各語言（如 Python、JavaScript）的程式碼，迅速從構思進入實作。  
- **Matt** 補充說明，雖然市場上有 Vertex AI 與 AI Studio 兩個產品，前者針對企業級應用提供進階功能，而後者則主打簡易入門；但兩者透過統一 SDK，使得開發者不必重複編寫程式碼，輕鬆切換使用。

---

### Q2：提示工程（Prompt Engineering）的演進  
**問題內容：**  
請問從 Palm 2、GPT-3 等早期模型至今，提示工程技術如何演進？在多模態模型興起的情況下，未來又會如何發展？

**專家觀點：**  
- **Kieran** 回顧早期模型僅具預測功能，當時透過各種試驗性技巧（如 chain-of-thought、設定角色等）來提升實用性；隨著指令調整技術的進步，模型開始能依照精心設計的提示回應特定任務。  
- 他預期未來終端用戶可以免除繁瑣的提示設計，而開發者將能依據標準化的設計模式，快速打造符合應用需求的系統。

---

### Q3：Vertex AI 與企業 AI 趨勢  
**問題內容：**  
面對 Vertex AI 持續演進，新興的企業 AI 趨勢有哪些？它如何協助企業將這些趨勢轉化為實際效益？

**專家觀點：**  
- **Warren** 說明，企業現正從單純處理非結構化數據，進入能進行深度研究與比較分析的階段，模型甚至能在缺乏最新資訊時自動調用工具進行數據補充。  
- **Arena** 補充，針對代理式工作流程（agentic workflows）的評估方法也日益重要，未來將有更多針對評估與驗證的技術幫助企業提升決策準確度。

---

### Q4：未來 1 至 3 年 AI 的突破與限制  
**問題內容：**  
未來一到三年，您認為基礎模型將解鎖哪些目前看似困難或不可能完成的任務？相對地，又有哪些固有限制可能會持續存在？

**專家觀點：**  
- **Matt** 強調，未來短短幾年內，AI 將顛覆軟體開發與應用方式，帶來前所未有的變革。  
- **Logan** 提到，即使技術進步，若缺乏充分上下文，模型仍難以達到理想效果，未來可能會自動詢問澄清問題，但使用者仍需提供完整背景。  
- **Arena** 與 **Warren** 分別補充，儘管期望提示工程能逐漸自動化，但模型永遠無法「讀心」，而企業內部流程的僵化也可能持續成為技術落地的障礙。

---

### Q5：提升 AI 系統能源效率的策略  
**問題內容（社群提問）：**  
如何優化 AI 系統設計與提示工程，提高能源效率與運算性能（速度與準確度），同時降低環境影響並保持模型輸出品質？

**專家觀點：**  
- **Logan** 說明，透過 API 層面的提示快取（prompt caching）與批次處理（batch APIs），以及根據數據中心使用再生能源的時段調度運算，都可有效提升能源效率。  
- 他也提到，Google 正在投資較小型的模型與設備端運算，進一步降低運算能耗。

---

### Q6：如何降低評估模型中的偏誤  
**問題內容（社群提問）：**  
在選擇與自訂評估模型時，如何有效降低累積偏誤與準確性問題，而不僅僅依賴重複評估建立信心？

**專家觀點：**  
- **Arena** 建議從三個方向入手：  
  1. **模型基礎：** 選用先進模型並利用多重抽樣與順序翻轉來緩解偏誤；  
  2. **模型評估：** 使用少量數據檢驗評估模型與人類專家是否對齊；  
  3. **提示設計：** 以清晰、具體的提示開始，必要時引入更精細的評分標準或進行微調。

---

### Q7：提示工程的範疇與重要性  
**問題內容（社群提問）：**  
提示工程究竟是否僅指撰寫提示語？設定 token 數量、temperature、top-p 等參數是否也屬於提示工程？其用途與重要性又為何？

**專家觀點：**  
- 多位專家認為，提示工程涵蓋兩個層面：  
  - **輸入層面：** 撰寫適當的提示語，類似於傳統機器學習中的特徵工程；  
  - **輸出層面：** 調整生成參數（如 temperature、top-p、token 長度），以達到理想回應。  
- 當前，提示工程仍帶有一定的「藝術性」，需要反覆試驗與調整；未來則有望隨著設計模式與自動化技術的發展而變得更標準化。

---

### Q8：降低模型幻覺（Hallucination）的方法  
**問題內容：**  
針對大語言模型常見的幻覺問題，Google 在 Gemini 2 中採用了哪些方法來降低不正確或誤導性輸出？在降低幻覺與維持模型創意之間是否存在權衡？

**專家觀點：**  
- **Kieran** 表示，降低幻覺（即提升事實性）主要透過兩個方向：  
  1. **基於輸入：** 使用檢索增強生成（RAG）與搜尋定位技術，使模型依據可驗證的外部資料回應；  
  2. **內部調整：** 在提示中明確要求事實驗證，並運用自我修正機制來糾正錯誤。  
- 他也指出，調整 temperature 等參數可在一定程度上平衡事實性與創意，但如何找到最佳權衡仍需依據具體應用情境進行微調。

---

## Pop Quiz 課後練習
學習完第一天的內容，讓我們來驗收一下所學。


### Pop Quiz Q1
哪個 Gemini 配置設定用來控制下一個 token 的隨機性？

(A) temperature  
(B) top-K  
(C) top-P  
(D) 輸出 token 數量

??? 答案

    **正確答案：** A. temperature

    **解釋：** temperature 控制著模型生成時選擇下一個 token 的隨機程度，溫度越高結果越多變，反之則較為確定。

---

### Pop Quiz Q2
下列哪一項**不是**用來加速大語言模型推理的方法？

(A) quantization  
(B) distillation  
(C) flash attention  
(D) fine-tuning

??? 答案

    **正確答案：** D. fine-tuning

    **解釋：** fine-tuning 是用來調整模型以適應特定任務，不是用來加速推理過程的方法。

---

### Pop Quiz Q3
Gemini 模型的一大獨特特性是什麼？

(A) 首次引入 unsupervised pre-training  
(B) 支援多模態輸入  
(C) 僅為 decoder 模型  
(D) 可支援高達 200 萬 token 的上下文視窗

??? 答案

    **正確答案：** D. 可支援高達 200 萬 token 的上下文視窗

    **解釋：** 這項特性使 Gemini 模型能處理極大規模的輸入內容，從而擴大其應用範圍與靈活性。

---

### Pop Quiz Q4
RLHF 如何改善大語言模型？

(A) 透過大規模未標記文本訓練  
(B) 使用獎勵模型激勵生成更符合人類偏好的回答  
(C) 減少模型參數以加快推理  
(D) 轉換模型為遞迴神經網絡

??? 答案

    **正確答案：** B. 使用獎勵模型激勵生成更符合人類偏好的回答

    **解釋：** RLHF（Reinforcement Learning from Human Feedback）透過獎勵信號引導模型調整輸出，使回答更貼近人類期望。

---

### Pop Quiz Q5
哪一技術能提升模型推理能力，讓其產生中間推理步驟？

(A) zero-shot prompting  
(B) step back prompting  
(C) self-consistent prompting  
(D) Chain of Thought prompting

??? 答案

    **正確答案：** D. Chain of Thought prompting

    **解釋：** Chain of Thought prompting 鼓勵模型在回答前展示中間推理過程，有助於生成更精確、合理的答案。

---

### Pop Quiz Q6（額外題）
運行 30 億(3b)參數模型（使用標準浮點精度）最低需要多少 GPU 記憶體？

(A) 3 GB  
(B) 6 GB  
(C) 12 GB  
(D) 24 GB

??? 答案

    **正確答案：** C. 12 GB

    **解釋：** 根據相關資料，運行此類模型所需的最低 GPU 記憶體為 12 GB，是基於標準浮點精度的要求。




