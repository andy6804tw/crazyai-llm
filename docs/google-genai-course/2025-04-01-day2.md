
# [Day 2] Embeddings 與向量資料庫

在第二天的課程中，你將學習與了解 embeddings 與向量資料庫（或向量資料庫/資料庫）的基本概念及其應用。透過本單元，你不僅會掌握如何利用這些技術將即時或專業資料引入大型語言模型（LLM）的應用，還能學習到利用向量的幾何特性來分類與比較文字資料，以及如何評估 embeddings 的效果。


## 本單元內容

- **🎙️ Podcast 聆聽**  
    收聽本單元的[Podcast 摘要](https://www.youtube.com/watch?v=xCAVsst6WJ8&list=PLqFaTIg4myu_yKJpvF8WE2JfaG5kGuvoE&index=3)，先行瞭解 embeddings 與向量資料庫的基本原理。  

- **📄 白皮書閱讀**  
    閱讀「[Embeddings and Vector Stores/ Databases](https://www.kaggle.com/whitepaper-embeddings-and-vector-stores)」白皮書，進一步深入學習相關理論與技術細節。

- **💻 Kaggle 實作練習**  
    透過實作練習，你將完成以下項目：
    1. [建立 RAG 問答系統](https://www.kaggle.com/code/markishere/day-2-document-q-a-with-rag)
    2. [探索文字相似度](https://www.kaggle.com/code/markishere/day-2-embeddings-and-similarity-scores)
    3. [使用 Keras 建立神經分類網路](https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras)


| 名稱                            | 範例程式 (zh_TW)                                                                                                                                                                                                                                                                            | 說明                                                                                             |
|---------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| 建立 RAG 問答系統               | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/andy6804tw/crazyai-llm/blob/main/docs/google-genai-course/code/colab/zh-TW/day-2-document-q-a-with-rag-zh-TW.ipynb) [![Open In Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/andy6804tw/crazyai-llm/main/docs/google-genai-course/code/kaggle/zh-TW/day-2-document-q-a-with-rag.ipynb) | 利用自訂文件構建一個基於 RAG 的問答系統，從自訂資料中檢索並生成答案。                                           |
| 探索文字相似度                   | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/andy6804tw/crazyai-llm/blob/main/docs/google-genai-course/code/colab/zh-TW/day-2-embeddings-and-similarity-scores.ipynb) [![Open In Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/andy6804tw/crazyai-llm/main/docs/google-genai-course/code/kaggle/zh-TW/day-2-embeddings-and-similarity-scores.ipynb) | 使用 embeddings 技術分析與比較文字資料之間的相似度，瞭解向量如何反映文字間的語意關係。                           |
| 使用 Keras 建立神經分類網路     | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/andy6804tw/crazyai-llm/blob/main/docs/google-genai-course/code/colab/zh-TW/day-2-classifying-embeddings-with-keras.ipynb) [![Open In Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/andy6804tw/crazyai-llm/main/docs/google-genai-course/code/kaggle/zh-TW/day-2-classifying-embeddings-with-keras.ipynb) | 透過 embeddings 作為輸入特徵，利用 Keras 建立神經網路進行文本分類，掌握向量技術在實際任務中的應用。                |

!!! info "本日學習重點"

        今天的課程主要讓你瞭解以下內容：

        - **概念基礎：**  
        了解 embeddings 與向量資料庫的核心概念，並學習這些技術如何幫助你將即時或專業資料整合進 LLM 應用中。

        - **向量的幾何應用：**  
        探索向量資料在分類與比較文字方面的能力，從中瞭解如何透過數學與幾何方法處理語意資訊。

        - **評估方法：**  
        學習如何評估 embeddings 的效能，確保在實際應用中能夠取得準確且高效的結果。

        透過今天的課程，你將獲得應用 embeddings 與向量資料庫的實作能力，能夠將豐富的資料整合進你的大型語言模型應用中，並利用向量技術進行更精確的資料分類、比較與檢索。

---

## Day 2 直播精華整理
嵌入是數據（如文字、圖片）的數值向量表示，能將不同數據映射到同一語意空間，用距離代表語意相似度，方便比較與作為下游任務的輸入。 我們探討了文字嵌入（從 word2vec 到 BERT、Gemini）、圖片與多模態嵌入，以及結構化數據和圖形的嵌入方法。 訓練常使用雙編碼器與對比損失，評估則看精確度與召回率等指標。 為了快速搜尋數十億向量，我們介紹了近似最近鄰 (ANN) 演算法（如 ScaNN、HNSW），它們犧牲微小精度換取巨大速度提升。 向量資料庫正是利用這些演算法來高效儲存、管理、查詢嵌入。 最後，我們討論了應用，如搜尋、推薦、檢索增強生成 (RAG) 等，嵌入為 RAG 提供了生成更真實、有根據答案所需的上下文。

![](./images/img-day2-1.png)


## Q&A 專家問答
### Q1：嵌入技術的進展與最佳實踐  
**問題內容：**  
在生成能夠捕捉細微語意（特別是針對專業領域或多模態資料）的嵌入向量方面，有哪些最新進展與最佳實踐？嵌入模型的選擇對下游向量搜尋任務的效能影響大嗎？

**專家觀點：**  

- **Andre** 表示，最新的趨勢在於整合大型語言模型 (LLM) 作為嵌入模型的預訓練骨幹，使得嵌入模型能夠利用多語言與多模態的理解能力；他也提到了 DeepMind 推出的 TIPS 模型（Text Image Pretraining with Spatial awareness），用來解決多模態嵌入中缺乏空間感知的問題。  
- **Howard** 補充說，Matryoshka 嵌入技術可使不同長度的嵌入前綴都具有效用，這讓我們能根據需求調整儲存的維度，同時也強調了利用 LLM 進行數據整理的重要性。

---

### Q2：整合向量搜尋至現有資料庫 vs. 專用向量資料庫  
**問題內容：**  
將向量搜尋功能整合進現有資料庫系統（例如 AlloyDB）與使用專用向量資料庫相比，各自的主要架構權衡是什麼？請簡述 AlloyDB 的特色與優勢。

**專家觀點：**  

- **Allan** 解釋，AlloyDB 是 GCP 提供的全相容 PostgreSQL 資料庫，經過架構創新後比傳統開源資料庫更快速；其內建向量搜尋能力（採用 ScaNN 演算法）能夠結合結構化資料與向量搜尋，讓使用者能在同一系統與 SQL 介面下完成多重查詢。  
- 他也指出，若資料主要為非結構化數據（如影像、文件），專用向量資料庫則較適合，但這通常會伴隨較高的成本及較寬鬆的數據一致性要求。

---

### Q3：向量嵌入與資料庫對企業數據架構的影響與挑戰  
**問題內容：**  
從策略層面來看，向量嵌入與向量資料庫技術的迅速發展，將如何影響企業數據架構與 AI 應用？企業在大規模採用這些技術時面臨哪些主要挑戰？

**專家觀點：**  

- **Patricia** 指出，這場技術變革意味著企業必須從傳統 SQL 精確匹配轉向建立多維度索引，並處理多模態資料。主要挑戰包括：  
    1. 部署與維護的成本與擴展性。  
    2. 缺乏統一的行業標準，導致整合與互操作性問題。  
    3. 專業人才不足，難以應對新技術的學習與應用。  
    4. 數據治理、安全性與合規性方面的要求日益嚴格。

---

### Q4：提升向量搜尋關聯性的高階技術  
**問題內容：**  
除了基本的餘弦相似度或歐幾里得距離之外，還有哪些進階技術（例如元數據過濾、混合搜尋、重新排序）可以進一步提升向量搜尋結果的相關性與準確性？這些技術如何整合到平台中？

**專家觀點：**  

- **Chuck** 表示，在採用進階技術前，必須先建立完善的評估機制。  
  - 混合搜尋結合了語意嵌入與傳統關鍵字匹配，能夠同時處理同義詞及相關概念。  
  - 重新排序技術則能根據資料來源的可信度對結果進行調整，但必須考量查詢延遲與系統吞吐量的平衡。

---

### Q5：如何升級嵌入模型？  
**問題內容：**  
當新一代嵌入模型問世時，是否必須重新生成資料庫中所有數據的嵌入？是否有更有效率的升級方法？

**專家觀點：**  

- **Chuck** 指出，由於不同嵌入模型之間通常不相容，因此更換模型時必須重新計算所有數據的嵌入。  
- **Howard** 補充，目前已有研究在探索如何將舊嵌入映射到新嵌入，但此技術仍處於試驗階段，尚未大規模部署。

---

### Q6：RAG 系統中文件與查詢使用不同嵌入模型的影響  
**問題內容：**  
在 RAG 系統中，如果文件與查詢使用不同的嵌入模型，會對檢索準確性及 LLM 生成回答的品質產生何種影響？

**專家觀點：**  

- **Shiai** 強調，為確保查詢與文件能夠映射到相同的語意空間，必須使用相同的嵌入模型。  
- 使用不同模型可能導致向量空間不一致，進而降低檢索效果並影響最終回答的準確性。

---

### Q7：如何處理 RAG 系統中的數據更新與時效性 (Drift)？  
**問題內容：**  
在動態或即時應用中，如何確保 RAG 系統中的查詢結果仍能與最新數據保持關聯性？系統該如何應對數據漂移？

**專家觀點：**  

- **Anant** 提到，監測嵌入隨時間的漂移是非常重要的，並建議使用低維度嵌入與增量索引技術以降低更新延遲與計算成本。  
- **Patricia** 補充，利用變更數據捕獲 (CDC) 以及即時 RAG 架構，可以有效應對數據變動。  
- **Allan** 則強調，傳統資料庫在事務一致性方面具備優勢，能夠即時反映數據更新，避免最終一致性問題。

---

### Q8：單一多模態模型 vs. 獨立單模態模型精度比較  
**問題內容：**  
在處理圖像與文字嵌入任務中，單一多模態模型與獨立單模態模型的精度比較如何？哪種模型更適合跨模態檢索？

**專家觀點：**  

- **Andre** 說明，多模態模型能夠同時處理不同模態的數據，具備跨模態檢索的優勢，但在單一模態的評估上，表現不一定超過專門的單模態模型。  
- **Howard** 補充，多模態模型利用大量線上圖文數據進行訓練，能將不同模態數據映射到共享嵌入空間，預期未來其單一模態精度將持續提升。

---

## Pop Quiz 課後練習

來驗收一下今天「生成式 AI 代理」的學習成果吧！

### Pop Quiz Q1
哪一項最能正確描述生成式 AI 代理？

(A) 只能生成文字的語言模型  
(B) 能夠觀察、推理並利用工具執行任務的應用程式  
(C) 一種用於資料儲存的數據庫  
(D) 用於訓練 AI 模型的硬體設備  

??? 答案

    **正確答案：** B. 能夠觀察、推理並利用工具執行任務的應用程式

    **解釋：** 生成式 AI 代理不僅僅是單純的語言模型，而是結合模型、工具呼叫及調度層等核心組件，協同完成特定任務。

---

### Pop Quiz Q2
在生成式 AI 代理的核心組成中，哪個部分主要負責管理代理內部的推理與行動流程？

(A) 模型  
(B) 調度層  
(C) 工具呼叫  
(D) 數據存儲  

??? 答案

    **正確答案：** B. 調度層

    **解釋：** 調度層負責協調代理的內部思考與行動循環，確保代理能夠根據預定邏輯進行決策與執行，而非單純依賴模型生成文字或數據存取。

---

### Pop Quiz Q3
關於生成式 AI 代理中使用的「函數調用」，下列何者描述正確？

(A) 允許代理直接調用外部 API 以取得最新資訊  
(B) 僅用於生成文字，不會調用任何外部資源  
(C) 僅能調用一次，無法進行多次操作  
(D) 用來儲存代理的設定參數  

??? 答案

    **正確答案：** A. 允許代理直接調用外部 API 以取得最新資訊

    **解釋：** 函數調用使代理能夠動態地調用外部工具或 API，從而獲取即時且真實的數據，並進一步支持任務執行。

---

### Pop Quiz Q4
在生成式 AI 代理中，數據存儲的主要作用是什麼？

(A) 儲存代理的設定與參數  
(B) 為代理提供即時且動態的資料存取能力  
(C) 控制代理的推理流程  
(D) 驗證代理生成內容的準確性  

??? 答案

    **正確答案：** B. 為代理提供即時且動態的資料存取能力

    **解釋：** 數據存儲（Data Stores）主要用於存取與管理外部資料，讓代理能夠基於最新資訊產生更具針對性的回應。

---

### Pop Quiz Q5
關於多代理系統（Multi-agent systems），下列哪項敘述正確？

(A) 多代理系統指的是單一模型處理所有任務  
(B) 多代理系統中，各專家代理協同合作，共同完成複雜任務  
(C) 多代理系統只適用於處理簡單任務  
(D) 多代理系統完全不需要人類介入  

??? 答案

    **正確答案：** B. 多代理系統中，各專家代理協同合作，共同完成複雜任務

    **解釋：** 多代理系統利用不同專長的代理協同合作，以解決單一代理難以應付的複雜任務，進而提升整體系統效能。

---

### Pop Quiz Q6
在生成式 AI 代理中，為什麼需要使用工具呼叫（如 API 調用）？

(A) 以提升生成文字的速度  
(B) 讓代理能夠獲取即時且真實世界的資料並執行相關操作  
(C) 僅用於改善模型的語言生成效果  
(D) 工具呼叫僅能用來加速推理速度  

??? 答案

    **正確答案：** B. 讓代理能夠獲取即時且真實世界的資料並執行相關操作

    **解釋：** 工具呼叫使代理能夠超越模型內部知識的限制，透過調用外部資源取得最新數據，從而生成更具時效性與精確性的回應。


### Pop Quiz Q2
相較於其他近似最近鄰 (ANN) 演算法，ScaNN 的一個主要優勢是什麼？

(A) 廣泛開源可用  
(B) 專為高維數據設計，且具有出色的速度與準確度權衡  
(C) ScaNN 只返回精確匹配結果  
(D) 基於簡單的雜湊技術，計算開銷低  

??? 答案

    **正確答案：**   B. 專為高維數據設計，且具有出色的速度與準確度權衡

    **解釋：**   ScaNN 是 Google 開發的先進 ANN 演算法，特別擅長處理高維數據，並能在速度和準確度之間取得良好平衡。

---

### Pop Quiz Q3
對於生成文件嵌入，詞袋模型 (Bag-of-Words) 的主要缺點是什麼？

(A) 忽略詞序和語意  
(B) 計算成本高昂，需要大量數據  
(C) 無法用於語意搜尋或主題發現  
(D) 只對短文件有效，無法捕捉長距離依賴關係  

??? 答案

    **正確答案：**   A. 忽略詞序和語意

    **解釋：**   詞袋模型只考慮詞頻，完全忽略了詞語的順序和它們組合起來的深層含義。

---

### Pop Quiz Q4
使用嵌入進行搜尋時，一個常見的挑戰及應對方法是什麼？

(A) 嵌入無法處理大型數據集，必須使用較小數據集  
(B) 嵌入總是優於傳統搜尋，無需結合使用  
(C) 嵌入可能無法很好地捕捉字面資訊，應與全文搜尋結合  
(D) 嵌入變化太頻繁，必須阻止更新  

??? 答案

    **正確答案：**   C. 嵌入可能無法很好地捕捉字面資訊，應與全文搜尋結合

    **解釋：**   嵌入擅長語意匹配，但對精確的字詞匹配可能不夠敏感。結合傳統的全文搜尋（關鍵字搜尋）可以互補，達到更好的效果（即混合搜尋）。

---

### Pop Quiz Q5
使用局部敏感雜湊 (Locality Sensitive Hashing, LSH) 進行向量搜尋的主要優點是什麼？

(A) 保證找到精確的最近鄰  
(B) 透過將相似項目分組到雜湊桶中來縮小搜尋空間  
(C) 唯一適用於高維向量的方法  
(D) 總能提供速度與準確度之間的最佳權衡  

??? 答案

    **正確答案：**   B. 透過將相似項目分組到雜湊桶中來縮小搜尋空間

    **解釋：**   LSH 的核心思想是設計雜湊函數，讓相似的向量更有可能碰撞到同一個桶中，從而只需在少量桶內進行比較，大幅減少搜尋範圍。
